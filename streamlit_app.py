# ==============================================================================
#  NÄ°HAÄ° KOD (v49.0): OdaklanmÄ±ÅŸ X TarayÄ±cÄ±sÄ±
#  AMAÃ‡: Sadece X (Twitter) Ã¼zerinde maliyetsiz arama yaparak tesis adÄ± bulmak.
# ==============================================================================
import streamlit as st
import requests
from bs4 import BeautifulSoup
from openai import OpenAI
from urllib.parse import quote
import re

# ------------------------------------------------------------------------------
# 1. TEMEL AYARLAR
# ------------------------------------------------------------------------------
st.set_page_config(layout="wide", page_title="OdaklanmÄ±ÅŸ X TarayÄ±cÄ±sÄ±")
st.title("ğŸ›°ï¸ OdaklanmÄ±ÅŸ X (Twitter) TarayÄ±cÄ±sÄ±")
st.info("Bu araÃ§, API kullanmadan doÄŸrudan X Ã¼zerinde arama yaparak endÃ¼striyel hasar olaylarÄ±ndaki tesis adlarÄ±nÄ± bulmaya odaklanmÄ±ÅŸtÄ±r.")

# --- API BaÄŸlantÄ±sÄ±
grok_api_key = st.secrets.get("GROK_API_KEY")
client = OpenAI(api_key=grok_api_key, base_url="https://api.x.ai/v1") if grok_api_key else None

# ------------------------------------------------------------------------------
# 2. Ã‡EKÄ°RDEK FONKSÄ°YONLAR
# ------------------------------------------------------------------------------

@st.cache_data(ttl=300, show_spinner="X arama sonuÃ§larÄ± taranÄ±yor...")
def scrape_x_search(search_query):
    """
    Verilen arama sorgusu ile X'in web arayÃ¼zÃ¼nÃ¼ tarar ve sayfanÄ±n ham metin iÃ§eriÄŸini dÃ¶ndÃ¼rÃ¼r.
    Bu yÃ¶ntem kÄ±rÄ±lgandÄ±r ve X'in gÃ¼ncellemeleriyle bozulabilir.
    """
    headers = {
        'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/91.0.4472.124 Safari/537.36'
    }
    # GeliÅŸmiÅŸ arama URL'si kullanarak daha isabetli sonuÃ§lar hedeflenir
    url = f"https://twitter.com/search?q={quote(search_query)}&src=typed_query&f=live"
    
    try:
        response = requests.get(url, headers=headers, timeout=20)
        response.raise_for_status()
        soup = BeautifulSoup(response.text, 'html.parser')
        # Sayfadaki tÃ¼m gÃ¶rÃ¼nÃ¼r metinleri temiz bir ÅŸekilde al
        return soup.get_text(separator='\n', strip=True)
    except requests.exceptions.RequestException as e:
        st.error(f"X'e baÄŸlanÄ±rken bir aÄŸ hatasÄ± oluÅŸtu. EngellenmiÅŸ olabiliriz. Hata: {e}")
        return None
    except Exception as e:
        st.error(f"Sayfa iÅŸlenirken beklenmedik bir hata oluÅŸtu: {e}")
        return None

@st.cache_data(ttl=3600, show_spinner="AI, taranan metinleri analiz ediyor...")
def extract_facility_tweets_from_text(_client, raw_text):
    """
    Ham metin iÃ§erisinden, ÅŸirket/tesis adÄ± iÃ§eren ilgili tweet'leri AI ile ayÄ±klar.
    """
    if not raw_text or len(raw_text) < 100:
        return "Taranan metin Ã§ok kÄ±sa veya boÅŸ, analiz yapÄ±lamadÄ±."

    prompt = f"""
    Sen, yapÄ±sal olmayan metinlerden bilgi Ã§Ä±karma konusunda uzman bir OSINT analistisin.
    Sana, bir X (Twitter) arama sayfasÄ±ndan taranmÄ±ÅŸ ham metin veriyorum.

    GÃ–REVÄ°N:
    1.  Bu metin yÄ±ÄŸÄ±nÄ± iÃ§indeki bireysel tweet'leri bul.
    2.  Sadece ve sadece bir endÃ¼striyel tesisin (fabrika, depo, sanayi tesisi vb.) **ticari unvanÄ±nÄ±** veya **spesifik adÄ±nÄ±** iÃ§eren tweet'leri ayÄ±kla. Genel ifadeleri ("bir fabrikada yangÄ±n") gÃ¶rmezden gel.
    3.  BulduÄŸun her bir anlamlÄ± tweet'i tam metin olarak, baÅŸÄ±na tire (-) koyarak listele.

    EÄŸer metin iÃ§inde spesifik bir ÅŸirket adÄ± geÃ§en ilgili bir tweet bulamazsan, sadece "Spesifik bir ÅŸirket adÄ± iÃ§eren tweet bulunamadÄ±." yaz.

    HAM METÄ°N:
    ---
    {raw_text[:15000]} 
    ---
    """
    try:
        response = _client.chat.completions.create(
            model="grok-4-fast-reasoning",
            messages=[{"role": "user", "content": prompt}],
            max_tokens=2048,
            temperature=0.0,
            timeout=90.0
        )
        return response.choices[0].message.content
    except Exception as e:
        return f"AI analizi sÄ±rasÄ±nda bir hata oluÅŸtu: {e}"

# ------------------------------------------------------------------------------
# 3. STREAMLIT ARAYÃœZÃœ
# ------------------------------------------------------------------------------

st.subheader("1. AdÄ±m: Arama Sorgusu Girin")
search_query = st.text_input(
    "Aramak istediÄŸiniz olayÄ±n anahtar kelimelerini girin (Ã¶rn: Gebze OSB patlama)",
    placeholder="Ã¶rn: DilovasÄ± kimya fabrikasÄ± yangÄ±n"
)

if st.button("X'te Tara ve Analiz Et", type="primary", use_container_width=True):
    if not client:
        st.error("LÃ¼tfen Grok API anahtarÄ±nÄ± Streamlit Secrets'a ekleyin.")
    elif not search_query:
        st.warning("LÃ¼tfen arama yapmak iÃ§in anahtar kelimeler girin.")
    else:
        st.session_state.search_query = search_query
        
        # Ã–nceki sonuÃ§larÄ± temizle
        st.session_state.raw_text = None
        st.session_state.final_report = None
        
        st.session_state.raw_text = scrape_x_search(search_query)
        if st.session_state.raw_text:
            st.session_state.final_report = extract_facility_tweets_from_text(client, st.session_state.raw_text)

if 'final_report' in st.session_state and st.session_state.final_report:
    st.markdown("---")
    st.subheader("2. AdÄ±m: Analiz SonuÃ§larÄ±")
    
    st.success("**AI TarafÄ±ndan AyÄ±klanan ve Tesis AdÄ± Ä°Ã§eren Tweetler:**")
    st.markdown(st.session_state.final_report)
    
    with st.expander("Taranan Ham Metni GÃ¶rÃ¼ntÃ¼le (Teknik Ä°nceleme Ä°Ã§in)"):
        st.text_area("Scraper'Ä±n X'ten Ã‡ektiÄŸi Ham Veri", st.session_state.get('raw_text', 'Veri bulunamadÄ±.'), height=300)
