# ==============================================================================
#  NÄ°HAÄ° KOD (v36.0): GeliÅŸmiÅŸ Metin Ã‡Ä±karma ve SaÄŸlamlaÅŸtÄ±rÄ±lmÄ±ÅŸ AI Mimarisi
# ==============================================================================
import streamlit as st
import pandas as pd
import folium
from streamlit_folium import folium_static
from openai import OpenAI
import json
import re
import requests
import feedparser
from urllib.parse import quote, urlparse
import time

# GeliÅŸmiÅŸ metin Ã§Ä±karma kÃ¼tÃ¼phaneleri
import trafilatura
from bs4 import BeautifulSoup
import readability

# ------------------------------------------------------------------------------
# 1. TEMEL AYARLAR
# ------------------------------------------------------------------------------
st.set_page_config(layout="wide", page_title="EndÃ¼striyel Hasar Analizi")
st.title("ğŸ›°ï¸ AkÄ±llÄ± EndÃ¼striyel Hasar Analiz Motoru")

# --- API BaÄŸlantÄ±larÄ± ---
grok_api_key = st.secrets.get("GROK_API_KEY")
google_api_key = st.secrets.get("GOOGLE_MAPS_API_KEY")
client = OpenAI(api_key=grok_api_key, base_url="https://api.x.ai/v1") if grok_api_key else None

# ------------------------------------------------------------------------------
# 2. Ã‡EKÄ°RDEK FONKSÄ°YONLAR (TÃœMÃœ YENÄ°LENDÄ° VE GÃœÃ‡LENDÄ°RÄ°LDÄ°)
# ------------------------------------------------------------------------------

# AdÄ±m 1: GeliÅŸtirilmiÅŸ RSS Fonksiyonu
@st.cache_data(ttl=600)
def get_latest_event_candidate_from_rss():
    """Tarihe gÃ¶re sÄ±ralanmÄ±ÅŸ ve tekilleÅŸtirilmiÅŸ en gÃ¼ncel haberi bulur."""
    q = '("fabrika yangÄ±nÄ±" OR "sanayi tesisi" OR "OSB yangÄ±n" OR "liman kaza" OR "depo patlamasÄ±" OR "enerji santrali")'
    rss_url = f"https://news.google.com/rss/search?q={quote(q)}+when:7d&hl=tr&gl=TR&ceid=TR:tr"
    try:
        feed = feedparser.parse(rss_url)
        if not feed.entries: return None
        
        seen = set()
        entries = sorted(feed.entries, key=lambda e: getattr(e, "published_parsed", time.gmtime(0)), reverse=True)
        
        for e in entries:
            title = getattr(e, "title", "").strip().split(" - ")[0]
            link = getattr(e, "link", "").strip()
            dom = urlparse(link).netloc
            key = (title.lower(), dom)
            if key in seen or "news.google.com" in dom: continue
            
            seen.add(key)
            return {"headline": title, "url": link}
        return None
    except Exception as e:
        st.error(f"RSS eriÅŸim hatasÄ±: {e}"); return None

# AdÄ±m 2A: KatmanlÄ± Metin Ã‡Ä±karma Motoru
def fetch_article_text(url: str, timeout: int = 15) -> str:
    """Bir haber URL'sinden ana metni Ã§Ä±karÄ±r. SÄ±ra: trafilatura -> readability -> bs4."""
    try:
        resp = requests.get(url, headers={"User-Agent": "Mozilla/5.0"}, timeout=timeout)
        resp.raise_for_status()
        html_doc = resp.text
    except requests.exceptions.RequestException:
        return ""

    # 1. Katman: Trafilatura (En GÃ¼Ã§lÃ¼)
    extracted = trafilatura.extract(html_doc, include_comments=False, include_tables=False)
    if extracted and len(extracted.strip()) > 300:
        return extracted.strip()

    # 2. Katman: Readability (Ä°kinci Tercih)
    try:
        doc = readability.Document(html_doc)
        summary_html = doc.summary()
        soup = BeautifulSoup(summary_html, "lxml")
        text = soup.get_text(separator="\n", strip=True)
        if text and len(text.strip()) > 300:
            return text.strip()
    except Exception:
        pass

    # 3. Katman: BeautifulSoup (Temel Fallback)
    try:
        soup = BeautifulSoup(html_doc, "lxml")
        for element in soup(["script", "style", "header", "footer", "nav", "aside"]):
            element.decompose()
        paragraphs = [p.get_text(" ", strip=True) for p in soup.find_all("p")]
        text = "\n".join([p for p in paragraphs if len(p) > 50])
        return text.strip()
    except Exception:
        return ""

# AdÄ±m 2B: "AraÅŸtÄ±rmacÄ±" AI - Ã‡ekilen METÄ°NDEN Ã¶zet Ã§Ä±karÄ±r
@st.cache_data(ttl=3600)
def get_summary_from_text(_client, url):
    raw_text = fetch_article_text(url)
    if not raw_text or len(raw_text) < 300:
        st.error(f"Makale metni Ã§ekilemedi veya yetersiz. URL ({url}) eriÅŸilemez veya iÃ§eriÄŸi boÅŸ olabilir.")
        return None
    
    article_text = raw_text[:12000] # Token sÄ±nÄ±rÄ±nÄ± aÅŸmamak iÃ§in metni kÄ±salt

    prompt = f"""
    AÅŸaÄŸÄ±daki metin bir haber web sayfasÄ±ndan alÄ±nmÄ±ÅŸtÄ±r. Metni dikkatlice oku ve olayÄ±n tÃ¼m detaylarÄ±nÄ± (ne, nerede, ne zaman, neden, sonuÃ§larÄ±) iÃ§eren, tarafsÄ±z ve kapsamlÄ± bir Ã¶zet metin oluÅŸtur.

    HABER METNÄ°:
    {article_text}
    """
    try:
        response = _client.chat.completions.create(
            model="grok-4-fast-reasoning", messages=[{"role": "user", "content": prompt}], max_tokens=2048, temperature=0.0
        )
        return response.choices[0].message.content
    except Exception as e:
        st.error(f"AraÅŸtÄ±rmacÄ± AI (Ã–zet Ã‡Ä±karma) HatasÄ±: {e}"); return None

# AdÄ±m 3: GeliÅŸtirilmiÅŸ "Analist" AI ve GÃ¼venli JSON Ã‡Ä±karÄ±mÄ±
def extract_json_strict(text: str):
    """AI yanÄ±tÄ±ndan JSON'Ä± gÃ¼venli bir ÅŸekilde Ã§Ä±karÄ±r."""
    if not text: return None
    try: # Ã–nce doÄŸrudan parse etmeyi dene, en temiz yÃ¶ntem
        return json.loads(text)
    except json.JSONDecodeError: # BaÅŸarÄ±sÄ±z olursa, metin iÃ§indeki bloÄŸu ara
        match = re.search(r'\{.*\}', text, flags=re.DOTALL)
        if match:
            try:
                return json.loads(match.group(0))
            except json.JSONDecodeError:
                return None
    return None

@st.cache_data(ttl=3600)
def get_detailed_report_from_summary(_client, headline, summary_text):
    prompt = f"""
    Sen elit bir sigorta istihbarat analistisin. GÃ¶revin, sana verilen Ã¶zeti ve baÅŸlÄ±ktaki ipuÃ§larÄ±nÄ± kullanarak X (Twitter) Ã¼zerinde zihinsel bir araÅŸtÄ±rma yapmak ve aÅŸaÄŸÄ±daki JSON ÅŸemasÄ±na %100 uyacak ÅŸekilde bir rapor oluÅŸturmaktÄ±r. BilmediÄŸin alanlara "Tespit Edilemedi" yaz. ASLA bilgi uydurma.

    BAÅLIK: "{headline}"
    Ã–ZET METNÄ°: "{summary_text}"

    JSON ÅEMASI (SADECE BU FORMATTA Ã‡IKTI VER, AÃ‡IKLAMA EKLEME):
    {{
      "tesis_adi": "string", "tesis_adi_kanit": "string", "sehir_ilce": "string", "olay_tarihi": "string",
      "hasarin_nedeni": "string", "hasarin_fiziksel_boyutu": "string", "yapilan_mudahale": "string",
      "maddi_hasar_tahmini": "string", "kar_kaybi_tahmini": "string", "guncel_durum": "string",
      "cevreye_etki": "string", "latitude": "string", "longitude": "string", "gorsel_url": "string"
    }}
    """
    try:
        response = _client.chat.completions.create(model="grok-4-fast-reasoning", messages=[{"role": "user", "content": prompt}], max_tokens=4096, temperature=0.1)
        content = response.choices[0].message.content
        data = extract_json_strict(content)
        if data:
            return data
        else:
            st.error(f"Analist AI geÃ§erli bir JSON Ã¼retemedi. Ham yanÄ±t: {content}"); return None
    except Exception as e:
        st.error(f"Analist AI (Rapor OluÅŸturma) HatasÄ±: {e}"); return None

# AdÄ±m 4: GeliÅŸtirilmiÅŸ CoÄŸrafi ZenginleÅŸtirme
@st.cache_data(ttl=86400)
def find_neighboring_facilities(api_key, lat, lon, radius=1800):
    if not api_key or not lat or not lon: return []
    try:
        kw = quote("fabrika depo sanayi tesis OSB Ã¼retim")
        url = f"https://maps.googleapis.com/maps/api/place/nearbysearch/json?location={float(lat)},{float(lon)}&radius={int(radius)}&type=establishment&keyword={kw}&key={api_key}"
        response = requests.get(url, timeout=12)
        results = response.json().get('results', [])
        return [{"tesis_adi": p.get('name'), "tip": ", ".join(p.get('types', [])), "adres": p.get('vicinity'), "lat": p.get('geometry', {}).get('location', {}).get('lat'), "lng": p.get('geometry', {}).get('location', {}).get('lng')} for p in results[:15]]
    except Exception as e:
        st.warning(f"Google Places API hatasÄ±: {e}"); return []


# ------------------------------------------------------------------------------
# 3. ARAYÃœZ VE ANA Ä°ÅLEM AKIÅI
# ------------------------------------------------------------------------------
# (Bu kÄ±sÄ±m Ã¶nceki kodla bÃ¼yÃ¼k Ã¶lÃ§Ã¼de aynÄ±, sadece fonksiyon isimleri gÃ¼ncellendi)

st.sidebar.header("Tek Olay Analizi")
run_analysis = st.sidebar.button("En Son Ã–nemli OlayÄ± Bul ve Analiz Et", type="primary", use_container_width=True)
st.sidebar.caption("En gÃ¼ncel olayÄ± bulur, iÃ§eriÄŸini Ã§eker, Ã¶zetler ve detaylÄ± analiz eder.")

if 'report' not in st.session_state:
    st.session_state.report = None

if run_analysis:
    if not client:
        st.error("LÃ¼tfen Grok API anahtarÄ±nÄ± Streamlit Secrets'a ekleyin."); st.stop()

    with st.status("AkÄ±llÄ± Analiz sÃ¼reci yÃ¼rÃ¼tÃ¼lÃ¼yor...", expanded=True) as status:
        status.write("AÅŸama 1/4: Haber kaynaklarÄ± taranÄ±yor...")
        event_candidate = get_latest_event_candidate_from_rss()
        if not event_candidate:
            status.update(label="Hata! Uygun bir olay adayÄ± bulunamadÄ±.", state="error"); st.stop()
        
        status.write(f"Olay AdayÄ± Bulundu: **{event_candidate['headline']}**")
        status.write(f"AÅŸama 2/4: 'AraÅŸtÄ±rmacÄ± AI' Ã§alÄ±ÅŸÄ±yor: Haber iÃ§eriÄŸi Ã§ekiliyor ve Ã¶zetleniyor...")
        
        summary_text = get_summary_from_text(client, event_candidate['url'])
        if not summary_text:
            status.update(label="Hata! Haber metni Ã§ekilemedi veya Ã¶zetlenemedi.", state="error"); st.stop()

        status.write("AÅŸama 3/4: 'Analist AI' Ã§alÄ±ÅŸÄ±yor: Ã–zetlenmiÅŸ metinden detaylÄ± rapor oluÅŸturuluyor...")
        report = get_detailed_report_from_summary(client, event_candidate['headline'], summary_text)
        
        if report:
            report['kaynak_url'] = event_candidate['url']
            status.write("AÅŸama 4/4: Rapor zenginleÅŸtiriliyor: Google Maps verileri Ã§ekiliyor...")
            report['komsu_tesisler_harita'] = find_neighboring_facilities(google_api_key, report.get('latitude'), report.get('longitude'))
            st.session_state.report = report
            status.update(label="Analiz BaÅŸarÄ±yla TamamlandÄ±!", state="complete", expanded=False)
        else:
            st.session_state.report = None
            status.update(label="Analiz BaÅŸarÄ±sÄ±z Oldu!", state="error")

if st.session_state.report:
    report = st.session_state.report
    # (Rapor gÃ¶sterme kodunda deÄŸiÅŸiklik yok, Ã¶nceki haliyle Ã§alÄ±ÅŸacaktÄ±r)
    st.markdown("---")
    st.header(f"Analiz Raporu: {report.get('tesis_adi', 'Ä°simsiz Tesis')}")
    if report.get('gorsel_url') and 'http' in report.get('gorsel_url'):
        st.image(report['gorsel_url'], caption="Olay Yerinden GÃ¶rÃ¼ntÃ¼ (AI TarafÄ±ndan Bulundu)")
    st.info(f"**KanÄ±t:** *\"{report.get('tesis_adi_kanit', 'KanÄ±t bulunamadÄ±.')}\"*")
    
    st.subheader("Hasar ve Olay DetaylarÄ±")
    col1, col2 = st.columns(2)
    with col1:
        st.warning(f"**HasarÄ±n Nedeni:** {report.get('hasarin_nedeni', 'N/A')}")
        st.warning(f"**Fiziksel Boyutu:** {report.get('hasarin_fiziksel_boyutu', 'N/A')}")
    with col2:
        st.success(f"**YapÄ±lan MÃ¼dahale:** {report.get('yapilan_mudahale', 'N/A')}")
        st.error(f"**GÃ¼ncel Durum:** {report.get('guncel_durum', 'N/A')}")
    
    st.subheader("Finansal Etki Tahmini")
    col3, col4 = st.columns(2)
    with col3: st.metric(label="Maddi Hasar Tahmini", value=report.get('maddi_hasar_tahmini', 'Tespit Edilemedi'))
    with col4: st.metric(label="Kar KaybÄ± Tahmini", value=report.get('kar_kaybi_tahmini', 'Tespit Edilemedi'))
    
    with st.expander("Harita, KomÅŸu Tesisler ve KaynaklarÄ± GÃ¶rÃ¼ntÃ¼le", expanded=True):
        lat, lon = report.get('latitude'), report.get('longitude')
        if lat and lon:
            try:
                m = folium.Map(location=[float(lat), float(lon)], zoom_start=14, tiles="CartoDB positron")
                folium.Marker([float(lat), float(lon)], popup=f"<b>{report.get('tesis_adi')}</b>", icon=folium.Icon(color='red', icon='fire')).add_to(m)
                neighbors = report.get('komsu_tesisler_harita', [])
                for neighbor in neighbors:
                    if neighbor.get('lat') and neighbor.get('lng'):
                        folium.Marker([neighbor['lat'], neighbor['lng']], popup=f"<b>{neighbor['tesis_adi']}</b><br>{neighbor.get('adres', '')}", tooltip=neighbor['tesis_adi'], icon=folium.Icon(color='blue', icon='industry', prefix='fa')).add_to(m)
                folium_static(m, height=500)
            except (ValueError, TypeError): st.warning("GeÃ§ersiz koordinat formatÄ±, harita Ã§izilemiyor.")
        else:
            st.info("Rapor, harita Ã§izimi iÃ§in yeterli koordinat bilgisi iÃ§ermiyor.")

        st.markdown("##### KomÅŸu Tesisler (Google Harita Verisi)")
        st.table(pd.DataFrame(report.get('komsu_tesisler_harita', [])).rename(columns={"adres": "Adres"}))
        st.markdown(f"**Kaynak Link:** [{report.get('kaynak_url')}]({report.get('kaynak_url')})")
else:
    st.info("BaÅŸlamak iÃ§in lÃ¼tfen kenar Ã§ubuÄŸundaki butona tÄ±klayarak analiz sÃ¼recini baÅŸlatÄ±n.")
