# ==============================================================================
#      NÄ°HAÄ° KOD (v19.0): v4 TabanlÄ±, GeliÅŸmiÅŸ ve Stabil SÃ¼rÃ¼m
# ==============================================================================
import streamlit as st
import pandas as pd
import folium
from streamlit_folium import folium_static
from openai import OpenAI
import json
import re
import requests

# ------------------------------------------------------------------------------
# 1. TEMEL AYARLAR
# ------------------------------------------------------------------------------
st.set_page_config(layout="wide", page_title="EndÃ¼striyel Hasar Analiz Paneli")
st.title("ğŸ›°ï¸ AkÄ±llÄ± EndÃ¼striyel Hasar Analiz Paneli")

# --- API KonfigÃ¼rasyonlarÄ± ---
grok_api_key = st.secrets.get("GROK_API_KEY")
google_api_key = st.secrets.get("GOOGLE_MAPS_API_KEY")
client = OpenAI(api_key=grok_api_key, base_url="https://api.x.ai/v1") if grok_api_key else None

# ------------------------------------------------------------------------------
# 2. Ã‡EKÄ°RDEK FONKSÄ°YONLAR
# ------------------------------------------------------------------------------

# ANA ANALÄ°Z MOTORU: AI'dan bÃ¼tÃ¼nleÅŸik ve detaylÄ± bir rapor ister.
@st.cache_data(ttl=1800) # 30 dakikalÄ±k cache
def get_industrial_events_from_ai(_client):
    # GÃœNCELLEME: v17'deki en geliÅŸmiÅŸ ve zorlayÄ±cÄ± prompt'u v4'Ã¼n yapÄ±sÄ±na entegre ettik.
    prompt = f"""
    Sen, TÃ¼rkiye odaklÄ± Ã§alÄ±ÅŸan, elit seviye bir sigorta ve risk istihbarat analistisin. GÃ¶revinin merkezinde doÄŸruluk, kanÄ±t ve derinlemesine detay vardÄ±r. YÃ¼zeysel Ã¶zetler kabul edilemez.

    ANA GÃ–REVÄ°N: Web'i (haber ajanslarÄ±) ve X'i (Twitter) aktif olarak tarayarak TÃ¼rkiye'de son 15 gÃ¼n iÃ§inde meydana gelmiÅŸ, sigortacÄ±lÄ±k aÃ§Ä±sÄ±ndan en Ã¶nemli **en fazla 10 adet** endÃ¼striyel veya enerji tesisi hasar olayÄ±nÄ± bul.

    KRÄ°TÄ°K TALÄ°MATLAR:
    1.  **DERÄ°NLEMESÄ°NE BÄ°LGÄ° TOPLA:** Sadece baÅŸlÄ±klarÄ± deÄŸil, bulduÄŸun haber metinlerinin ve X paylaÅŸÄ±mlarÄ±nÄ±n iÃ§eriÄŸini OKU.
    2.  **KAYNAK GÃ–STERME ZORUNLUDUR:** Ã–zellikle tesis adÄ± ve hasar tahmini gibi kritik bilgiler iÃ§in kaynaÄŸÄ±nÄ± belirt.
    3.  **TEKÄ°LLEÅTÄ°R:** FarklÄ± kaynaklardaki aynÄ± olayÄ± tek bir zengin rapor altÄ±nda birleÅŸtir.

    Ã‡IKTI FORMATI: BulgularÄ±nÄ±, her bir olay iÃ§in aÅŸaÄŸÄ±daki detaylÄ± anahtarlara sahip bir JSON nesnesi iÃ§eren bir JSON dizisi olarak dÃ¶ndÃ¼r.
    
    JSON NESNE YAPISI:
    - "tesis_adi": YÃ¼ksek doÄŸrulukla tespit edilmiÅŸ ticari unvan.
    - "tesis_adi_kaynak": Tesis adÄ±nÄ± hangi kaynaklara (X, haber ajansÄ± vb.) dayanarak bulduÄŸunun aÃ§Ä±klamasÄ±.
    - "sehir_ilce": OlayÄ±n yaÅŸandÄ±ÄŸÄ± yer.
    - "olay_tarihi": OlayÄ±n tarihi (YYYY-AA-GG formatÄ±nda).
    - "hasarin_nedeni": OlayÄ±n tahmini nedeni (Ã–rn: "Elektrik panosundaki kÄ±sa devre").
    - "hasarin_fiziksel_boyutu": HasarÄ±n fiziksel etkisi (Ã–rn: "FabrikanÄ±n 5000 metrekarelik depo bÃ¶lÃ¼mÃ¼ tamamen yandÄ±.").
    - "hasar_tahmini_parasal": Parasal hasar bilgisi ve kaynaÄŸÄ±.
    - "guncel_durum": Ãœretim durdu mu, soruÅŸturma baÅŸladÄ± mÄ± gibi en son bilgiler.
    - "latitude": Olay yerinin enlemi (Sadece sayÄ±, tahmin de olabilir).
    - "longitude": Olay yerinin boylamÄ± (Sadece sayÄ±, tahmin de olabilir).
    - "kaynak_urller": KullandÄ±ÄŸÄ±n tÃ¼m haber ve X linklerinin listesi (dizi).
    """
    try:
        response = _client.chat.completions.create(model="grok-4-fast-reasoning", messages=[{"role": "user", "content": prompt}], max_tokens=8192, temperature=0.1)
        content = response.choices[0].message.content
        match = re.search(r'\[.*\]', content, re.DOTALL)
        if match:
            df = pd.DataFrame(json.loads(match.group(0)))
            if not df.empty:
                df['olay_tarihi'] = pd.to_datetime(df['olay_tarihi'], errors='coerce')
                df['latitude'] = pd.to_numeric(df['latitude'], errors='coerce')
                df['longitude'] = pd.to_numeric(df['longitude'], errors='coerce')
                return df.sort_values(by='olay_tarihi', ascending=False).reset_index(drop=True)
        return pd.DataFrame()
    except Exception as e:
        st.error(f"Ana Analiz Motorunda Hata: {e}"); return pd.DataFrame()

# COÄRAFÄ° ZENGÄ°NLEÅTÄ°RME
@st.cache_data(ttl=86400)
def find_neighboring_facilities(api_key, lat, lon, radius=500):
    if not api_key or pd.isna(lat) or pd.isna(lon): return []
    try:
        url = f"https://maps.googleapis.com/maps/api/place/nearbysearch/json?location={lat},{lon}&radius={radius}&type=establishment&keyword=fabrika|depo|sanayi|tesis|lojistik|antrepo&key={api_key}"
        response = requests.get(url)
        results = response.json().get('results', [])
        return [{"tesis_adi": p.get('name'), "tip": ", ".join(p.get('types', [])), "konum": p.get('vicinity')} for p in results[:10]]
    except Exception as e:
        st.warning(f"Google Places API hatasÄ±: {e}"); return []

# ------------------------------------------------------------------------------
# 3. ARAYÃœZ VE ANA Ä°ÅLEM AKIÅI
# ------------------------------------------------------------------------------
st.sidebar.header("Analiz KontrolÃ¼")
run_analysis = st.sidebar.button("Son OlaylarÄ± Analiz Et", type="primary", use_container_width=True)
st.sidebar.caption("Web'i ve X'i tarayarak en gÃ¼ncel ve Ã¶nemli olaylarÄ± bulur, detaylÄ± analiz eder.")

if 'events_df' not in st.session_state:
    st.session_state.events_df = pd.DataFrame()

if run_analysis:
    if not client:
        st.error("LÃ¼tfen Grok API anahtarÄ±nÄ± Streamlit Secrets'a ekleyin."); st.stop()

    with st.spinner("Ana Analiz Motoru Ã§alÄ±ÅŸtÄ±rÄ±lÄ±yor... Bu iÅŸlem birkaÃ§ dakika sÃ¼rebilir."):
        # 1. AI'dan temel raporu al
        df = get_industrial_events_from_ai(client)
        
        # 2. Raporu Google Maps verisiyle zenginleÅŸtir
        if not df.empty:
            df['komsu_tesisler_harita'] = df.apply(
                lambda row: find_neighboring_facilities(google_api_key, row['latitude'], row['longitude']),
                axis=1
            )
        st.session_state.events_df = df

if not st.session_state.events_df.empty:
    df = st.session_state.events_df
    st.success(f"{len(df)} adet Ã¶nemli olay raporu oluÅŸturuldu.")
    
    # GÃœNCELLEME: RaporlarÄ± daha okunaklÄ± bir formatta, tek tek gÃ¶ster
    for index, row in df.iterrows():
        st.markdown("---")
        st.subheader(f"{row.get('tesis_adi', 'Ä°simsiz Tesis')} - {row.get('sehir_ilce', 'Konum Yok')}")
        st.caption(f"Olay Tarihi: {row.get('olay_tarihi', pd.NaT).strftime('%d %B %Y') if pd.notna(row.get('olay_tarihi')) else 'Bilinmiyor'} | Tesis AdÄ± KaynaÄŸÄ±: {row.get('tesis_adi_kaynak', 'N/A')}")

        col1, col2 = st.columns(2)
        with col1:
            st.info(f"**HasarÄ±n Nedeni:** {row.get('hasarin_nedeni', 'N/A')}")
        with col2:
            st.error(f"**GÃ¼ncel Durum:** {row.get('guncel_durum', 'N/A')}")

        st.warning(f"**HasarÄ±n Fiziksel Boyutu:** {row.get('hasarin_fiziksel_boyutu', 'N/A')}")
        st.metric(label="Parasal Hasar Tahmini", value=row.get('hasar_tahmini_parasal', 'Tespit Edilemedi'))

        with st.expander("Harita, KomÅŸu Tesisler ve KaynaklarÄ± GÃ¶rÃ¼ntÃ¼le"):
            lat, lon = row.get('latitude'), row.get('longitude')
            if pd.notna(lat) and pd.notna(lon):
                m = folium.Map(location=[lat, lon], zoom_start=15, tiles="CartoDB positron")
                folium.Marker([lat, lon], popup=f"<b>{row.get('tesis_adi')}</b>", icon=folium.Icon(color='red', icon='fire')).add_to(m)
                folium_static(m, height=400)
            else:
                st.info("Rapor, harita Ã§izimi iÃ§in yeterli koordinat bilgisi iÃ§ermiyor.")

            st.markdown("##### KomÅŸu Tesisler (Google Harita Verisi)")
            neighbors_data = row.get('komsu_tesisler_harita', [])
            if neighbors_data:
                st.table(pd.DataFrame(neighbors_data))
            else:
                st.write("YakÄ±n Ã§evrede harita servisinden tesis tespit edilemedi veya koordinat bilgisi yoktu.")
            
            st.markdown("##### Kaynak Linkler")
            kaynaklar = row.get('kaynak_urller', [])
            if kaynaklar:
                for link in kaynaklar:
                    st.markdown(f"- {link}")
            else:
                st.write("Kaynak link bulunamadÄ±.")
else:
    st.info("BaÅŸlamak iÃ§in lÃ¼tfen kenar Ã§ubuÄŸundaki 'Son OlaylarÄ± Analiz Et' butonuna tÄ±klayÄ±n.")
