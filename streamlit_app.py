# ==============================================================================
#  NÄ°HAÄ° KOD (v48.0): AkÄ±llÄ± Anahtar Kelime Motoru ile GÃ¼Ã§lendirilmiÅŸ TarayÄ±cÄ±
# ==============================================================================
import streamlit as st
import pandas as pd
import feedparser
from openai import OpenAI
import json
import re
from urllib.parse import quote
import folium
from streamlit_folium import folium_static
import requests
from bs4 import BeautifulSoup
from rapidfuzz import fuzz
import time

# ------------------------------------------------------------------------------
# 1. TEMEL AYARLAR VE YAPILANDIRMA
# ------------------------------------------------------------------------------
st.set_page_config(layout="wide", page_title="OSINT Hasar Tespiti")
st.title("ğŸ›°ï¸ OSINT TarayÄ±cÄ± & AI DoÄŸrulayÄ±cÄ± Motoru v48")

# --- API BaÄŸlantÄ±larÄ±
grok_api_key = st.secrets.get("GROK_API_KEY")
google_api_key = st.secrets.get("GOOGLE_MAPS_API_KEY")
client = OpenAI(api_key=grok_api_key, base_url="https://api.x.ai/v1") if grok_api_key else None

# --- Sabitler
RISK_TYPES = {"YangÄ±n": '"yangÄ±n"', "Patlama": '"patlama"', "EndÃ¼striyel Kaza": '"endÃ¼striyel kaza"', "Kimyasal SÄ±zÄ±ntÄ±": '"kimyasal sÄ±zÄ±ntÄ±"'}
CORPORATE_SUFFIXES = ['A.Å.', 'Holding', 'Grup', 'Plastik', 'Kimya', 'Sanayi', 'Tekstil', 'Lojistik', 'GÄ±da', 'FabrikasÄ±', 'Deposu', 'Tesisleri', 'Enerji', 'Ãœretim']

# ------------------------------------------------------------------------------
# 2. YENÄ° Ã‡EKÄ°RDEK FONKSÄ°YONLAR
# ------------------------------------------------------------------------------

@st.cache_data(ttl=900)
def get_initial_events(selected_risks):
    """Sol panel iÃ§in ilk haber listesini oluÅŸturur."""
    if not selected_risks: return []
    locations = '"fabrika" OR "sanayi" OR "OSB" OR "liman" OR "depo"'
    risk_query = " OR ".join([RISK_TYPES[risk] for risk in selected_risks])
    q = f'({locations}) AND ({risk_query})'; rss_url = f"https://news.google.com/rss/search?q={quote(q)}+when:7d&hl=tr&gl=TR&ceid=TR:tr"
    try:
        feed = feedparser.parse(rss_url)
        if not feed.entries: return []
        sorted_entries = sorted(feed.entries, key=lambda e: getattr(e, 'published_parsed', time.gmtime(0)), reverse=True)
        unique_articles, seen_headlines = [], []
        for entry in sorted_entries:
            headline = entry.title.split(" - ")[0].strip()
            if not any(fuzz.ratio(headline, seen) > 80 for seen in seen_headlines):
                summary = re.sub('<[^<]+?>', '', entry.get('summary', ''))
                unique_articles.append({"headline": headline, "snippet": summary[:150] + '...', "full_summary": summary, "url": entry.link})
                seen_headlines.append(headline)
        return unique_articles[:30]
    except Exception: return []

# YENÄ°: AkÄ±llÄ± Anahtar Kelime Motoru
@st.cache_data(ttl=86400, show_spinner="AkÄ±llÄ± anahtar kelimeler Ã¼retiliyor...")
def extract_keywords_for_search(_client, headline):
    """Bir haber baÅŸlÄ±ÄŸÄ±ndan, arama yapmak iÃ§in en uygun anahtar kelimeleri AI ile Ã§Ä±karÄ±r."""
    prompt = f"""
    Sen bir arama motoru optimizasyon uzmanÄ±sÄ±n. Sana verilen haber baÅŸlÄ±ÄŸÄ±nÄ± analiz et ve bu olayla ilgili internette arama yapmak iÃ§in en etkili, temiz ve gÃ¼Ã§lÃ¼ 3-4 anahtar kelimeyi belirle. Sadece konumu, tesis tipini ve olay tÃ¼rÃ¼nÃ¼ dikkate al.
    
    BaÅŸlÄ±k: "{headline}"
    
    Ã‡Ä±ktÄ± olarak sadece virgÃ¼lle ayrÄ±lmÄ±ÅŸ kelime listesi ver. Ã–rnek: ArnavutkÃ¶y, fabrika, patlama
    """
    try:
        response = _client.chat.completions.create(
            model="grok-4-fast-reasoning", messages=[{"role": "user", "content": prompt}],
            max_tokens=50, temperature=0.0
        )
        return response.choices[0].message.content.strip().split(',')
    except Exception:
        return headline.split() # AI baÅŸarÄ±sÄ±z olursa eski yÃ¶nteme dÃ¶n

@st.cache_data(ttl=3600, show_spinner="OSINT TaramasÄ± baÅŸlatÄ±ldÄ±: X ve Google taranÄ±yor...")
def run_multivector_scanner(keywords):
    """AkÄ±llÄ± anahtar kelimelerle Ã§ok vektÃ¶rlÃ¼ tarama yaparak aday isimleri bulur."""
    headers = {'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/91.0.4472.124 Safari/537.36'}
    candidates = set()
    search_query = " ".join(f'"{k.strip()}"' for k in keywords)

    # Ã‡ok VektÃ¶rlÃ¼ Tarama
    search_vectors = {
        "X (Twitter) TaramasÄ±": f"https://www.google.com/search?q={quote(search_query + ' site:twitter.com')}",
        "Genel BasÄ±n TaramasÄ±": f"https://www.google.com/search?q={quote(search_query)}"
    }
    
    for source, url in search_vectors.items():
        try:
            response = requests.get(url, headers=headers, timeout=15)
            soup = BeautifulSoup(response.text, 'html.parser')
            text_content = soup.get_text()
            pattern = r'\b[A-Z][A-Za-z]+(?:\s[A-Z][A-Za-z]+)*\s(?:' + '|'.join(CORPORATE_SUFFIXES) + r')\b'
            found_names = re.findall(pattern, text_content)
            for name in found_names:
                candidates.add(name.strip())
        except Exception as e:
            st.warning(f"{source} sÄ±rasÄ±nda hata: {e}")
            
    return list(candidates)

@st.cache_data(ttl=3600, show_spinner="AI DoÄŸrulayÄ±cÄ± Ã§alÄ±ÅŸÄ±yor: Adaylar ve kanÄ±tlar analiz ediliyor...")
def run_verifier_ai(_client, context, candidates):
    """TarayÄ±cÄ±dan gelen adaylarÄ± ve ana metni analiz ederek nihai raporu oluÅŸturur."""
    prompt = f"""
    Sen, bir OSINT analistisin. GÃ¶revin, sana sunulan kanÄ±tlarÄ± birleÅŸtirerek bir hasar raporu oluÅŸturmak. HalÃ¼sinasyona sÄ±fÄ±r toleransÄ±n var.
    KANIT PAKETÄ°:
    1. ANA HABER METNÄ°: "{context}"
    2. TARAYICI BULGULARI (Potansiyel Tesis AdlarÄ±): {candidates}
    GÃ–REVÄ°N:
    1. 'TARAYICI BULGULARI' listesindeki adaylardan hangisinin 'ANA HABER METNÄ°' ile en uyumlu olduÄŸunu tespit et.
    2. Tespit ettiÄŸin doÄŸru isim Ã¼zerinden, aÅŸaÄŸÄ±daki JSON formatÄ±nda detaylÄ± bir rapor oluÅŸtur.
    3. EÄŸer listedeki hiÃ§bir aday metinle uyuÅŸmuyorsa, "tesis_adi" alanÄ±na "Teyit Edilemedi" yaz.
    JSON Ã‡IKTISI (Sadece JSON ver):
    {{
      "tesis_adi": "DoÄŸruladÄ±ÄŸÄ±n ticari unvan.", "guven_skoru": "1-5 arasÄ± bir sayÄ±.",
      "kanit_zinciri": "Hangi adayÄ± neden seÃ§tiÄŸini ve metindeki hangi cÃ¼mlenin bu seÃ§imi desteklediÄŸini aÃ§Ä±kla.",
      "sehir_ilce": "Metinde geÃ§en net ÅŸehir ve ilÃ§e.", "hasarin_nedeni": "Hasar nedeni.",
      "hasarin_fiziksel_boyutu": "HasarÄ±n fiziksel kapsamÄ±.", "is_durmasi_etkisi": "Faaliyetin durmasÄ±na iliÅŸkin bilgi.",
      "tahmini_koordinat": {{"lat": "...", "lon": "..."}}
    }}
    """
    try:
        response = _client.chat.completions.create(
            model="grok-4-fast-reasoning", messages=[{"role": "user", "content": prompt}],
            max_tokens=4096, temperature=0.0, timeout=90.0
        )
        match = re.search(r'\{.*\}', response.choices[0].message.content, re.DOTALL)
        return json.loads(match.group(0)) if match else None
    except Exception as e:
        st.error(f"AI DoÄŸrulayÄ±cÄ± HatasÄ±: {e}"); return None

# CoÄŸrafi ZenginleÅŸtirme Fonksiyonu
@st.cache_data(ttl=86400)
def get_coords_from_google(api_key, address_text):
    if not api_key or not address_text: return None
    try:
        url = f"https://maps.googleapis.com/maps/api/geocode/json?address={quote(address_text)}&key={api_key}&language=tr&region=TR"
        response = requests.get(url); results = response.json().get('results', [])
        if results: return results[0].get('geometry', {}).get('location', {})
    except Exception: return None

# ------------------------------------------------------------------------------
# 5. STREAMLIT ARAYÃœZÃœ
# ------------------------------------------------------------------------------
if 'selected_risks' not in st.session_state: st.session_state.selected_risks = list(RISK_TYPES.keys())

col1, col2 = st.columns([1, 2], gap="large")

with col1: # SOL PANEL
    st.header("ğŸ“° Olay AkÄ±ÅŸÄ±")
    st.session_state.selected_risks = st.multiselect("Risk Tiplerini SeÃ§in:", options=list(RISK_TYPES.keys()), default=st.session_state.selected_risks)
    if st.button("Filtrele ve GÃ¼ncel OlaylarÄ± Tara", type="primary", use_container_width=True):
        st.session_state.initial_events = get_initial_events(st.session_state.selected_risks)
        st.session_state.selected_event = None; st.session_state.keywords = None; st.session_state.candidates = None; st.session_state.final_report = None
    
    if st.session_state.get('initial_events'):
        for event in st.session_state.initial_events:
            with st.container(border=True):
                st.markdown(f"**{event['headline']}**")
                st.caption(event['snippet'])
                if st.button("Bu OlayÄ± Analiz Et", key=event['url'], use_container_width=True):
                    st.session_state.selected_event = event
                    st.session_state.keywords = None; st.session_state.candidates = None; st.session_state.final_report = None
                    st.rerun()

with col2: # SAÄ PANEL
    st.header("ğŸ“ Analiz Paneli")
    if not st.session_state.get('selected_event'):
        st.info("LÃ¼tfen sol panelden bir olay seÃ§ip 'Bu OlayÄ± Analiz Et' butonuna tÄ±klayÄ±n.")
    else:
        event = st.session_state.selected_event
        st.subheader(event['headline'])

        # --- AÅAMA 1: AKILLI ANAHTAR KELÄ°ME ve TARAMA ---
        if st.button("1. AdÄ±m: Tara ve Aday Ä°simleri Bul", type="primary", use_container_width=True):
            st.session_state.keywords = extract_keywords_for_search(client, event['headline'])
            st.session_state.candidates = run_multivector_scanner(st.session_state.keywords)
            st.rerun()
        
        # --- AÅAMA 1 SONUÃ‡LARI VE AÅAMA 2 BUTONU ---
        if st.session_state.get('keywords'):
            st.info(f"**AkÄ±llÄ± Anahtar Kelimeler:** `{', '.join(st.session_state.keywords)}`")

        if st.session_state.get('candidates') is not None:
            candidates = st.session_state.candidates
            st.markdown("---")
            if not candidates:
                st.warning("Otomatik tarama sonucunda potansiyel bir tesis adÄ± adayÄ± bulunamadÄ±.")
            else:
                st.write("**Tarama Sonucu Bulunan Potansiyel Adaylar:**")
                st.write(f"`{', '.join(candidates)}`")
                
                if st.button("2. AdÄ±m: AdaylarÄ± DoÄŸrula ve Rapor OluÅŸtur", use_container_width=True):
                    st.session_state.final_report = run_verifier_ai(client, event['full_summary'], candidates)
                    st.rerun()
        
        # --- AÅAMA 2 SONUÃ‡LARI (NÄ°HAÄ° RAPOR) ---
        if st.session_state.get('final_report'):
            report = st.session_state.final_report
            st.markdown("---")
            col_title, col_score = st.columns([3, 1])
            col_title.subheader(f"DoÄŸrulanan Kimlik: {report.get('tesis_adi', 'Teyit Edilemedi')}")
            col_score.metric("GÃ¼ven Skoru", f"{report.get('guven_skoru', 0)}/5")
            st.info(f"**KanÄ±t Zinciri:** {report.get('kanit_zinciri', 'N/A')}")

            st.warning(f"**HasarÄ±n Nedeni:** {report.get('hasarin_nedeni', 'N/A')}")
            st.warning(f"**Fiziksel Boyutu:** {report.get('hasarin_fiziksel_boyutu', 'N/A')}")
            st.info(f"**Ä°ÅŸ DurmasÄ± Etkisi:** {report.get('is_durmasi_etkisi', 'N/A')}")
            
            # Harita
            coords = report.get('tahmini_koordinat', {})
            final_coords = None
            if coords and coords.get('lat'):
                try: final_coords = {'lat': float(coords['lat']), 'lng': float(coords['lon'])}
                except (ValueError, TypeError): final_coords = None
            
            if not final_coords:
                address = f"{report.get('tesis_adi', '')}, {report.get('sehir_ilce', '')}"
                if report.get('tesis_adi') != 'Teyit Edilemedi':
                    final_coords = get_coords_from_google(google_api_key, address)

            if final_coords:
                st.subheader("Olay Yeri HaritasÄ±")
                m = folium.Map(location=[final_coords['lat'], final_coords['lng']], zoom_start=14)
                folium.TileLayer('CartoDB positron').add_to(m)
                folium.Marker([final_coords['lat'], final_coords['lng']], popup=f"<b>{report.get('tesis_adi')}</b>", icon=folium.Icon(color='red', icon='fire')).add_to(m)
                folium_static(m, height=400)
            else:
                st.warning("Konum bilgisi bulunamadÄ±ÄŸÄ± iÃ§in harita oluÅŸturulamadÄ±.")
