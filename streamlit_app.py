# ==============================================================================
#           NÄ°HAÄ° KOD (v6): Ä°KÄ° AÅAMALI AKILLI ANALÄ°Z
# ==============================================================================
import streamlit as st
import pandas as pd
from datetime import datetime
import folium
from streamlit_folium import folium_static
from openai import OpenAI
import json
import re

# ------------------------------------------------------------------------------
# 1. TEMEL AYARLAR
# ------------------------------------------------------------------------------

st.set_page_config(layout="wide")
st.title("ğŸš¨ AkÄ±llÄ± EndÃ¼striyel Hasar Takip Platformu")
st.markdown("---")

API_SERVICE = "Grok_XAI" 
API_CONFIGS = {"Grok_XAI": {"base_url": "https://api.x.ai/v1", "model": "grok-4-fast-reasoning"}}
SELECTED_CONFIG = API_CONFIGS[API_SERVICE]
API_KEY_NAME = "GROK_API_KEY"
api_key = st.secrets.get(API_KEY_NAME)

# ------------------------------------------------------------------------------
# 2. API BAÄLANTI KONTROLÃœ
# ------------------------------------------------------------------------------

@st.cache_data(ttl=3600)
def validate_api_key(key, base_url, model):
    if not key: return False, "API AnahtarÄ± bulunamadÄ±.", "LÃ¼tfen Streamlit Secrets ayarlarÄ±nÄ±zÄ± kontrol edin."
    try:
        OpenAI(api_key=key, base_url=base_url).chat.completions.create(model=model, messages=[{"role": "user", "content": "Test"}], max_tokens=10)
        return True, f"API baÄŸlantÄ±sÄ± baÅŸarÄ±lÄ±: **{API_SERVICE} ({model})**", ""
    except Exception as e:
        return False, "API BaÄŸlantÄ± HatasÄ±.", f"Detay: {e}"

st.sidebar.subheader("âš™ï¸ API BaÄŸlantÄ± Durumu")
is_valid, status_message, solution_message = validate_api_key(api_key, SELECTED_CONFIG["base_url"], SELECTED_CONFIG["model"])
if is_valid:
    st.sidebar.success(f"âœ… {status_message}")
else:
    st.sidebar.error(f"âŒ {status_message}"); st.sidebar.warning(solution_message); st.stop()

# ------------------------------------------------------------------------------
# 3. YENÄ° Ä°KÄ° AÅAMALI VERÄ° Ã‡EKME FONKSÄ°YONLARI
# ------------------------------------------------------------------------------

# 1. AÅŸama: Sadece olaylarÄ± ve linklerini bulur. Basit ve hÄ±zlÄ±dÄ±r.
@st.cache_data(ttl=900) # Olay listesini 15 dakikada bir yenile
def find_latest_events(key, base_url, model, event_count=15):
    client = OpenAI(api_key=key, base_url=base_url)
    prompt = f"""
    TÃ¼rkiye'de yakÄ±n zamanda yaÅŸanmÄ±ÅŸ en son {event_count} Ã¶nemli endÃ¼striyel hasar olayÄ±nÄ± (fabrika yangÄ±nÄ±, patlama, kimyasal sÄ±zÄ±ntÄ± vb.) listele.
    Sadece teyit edilmiÅŸ haber kaynaklarÄ±nÄ± (AA, DHA, Ä°HA, NTV, HÃ¼rriyet, Valilik aÃ§Ä±klamalarÄ±) kullan.
    Ã‡Ä±ktÄ±yÄ±, aÅŸaÄŸÄ±daki anahtarlarÄ± iÃ§eren bir JSON dizisi olarak ver. BaÅŸka hiÃ§bir analiz yapma, sadece listele.
    - "headline": "OlayÄ±n kÄ±sa baÅŸlÄ±ÄŸÄ±"
    - "url": "Habere ait tam ve tÄ±klanabilir link"
    """
    try:
        response = client.chat.completions.create(model=model, messages=[{"role": "user", "content": prompt}], max_tokens=2048, temperature=0.0)
        content = response.choices[0].message.content.strip()
        match = re.search(r'\[.*\]', content, re.DOTALL)
        if match:
            return json.loads(match.group(0))
        return []
    except Exception:
        return []

# 2. AÅŸama: Tek bir haberi derinlemesine analiz eder. Her link iÃ§in ayrÄ± Ã§alÄ±ÅŸÄ±r ve sonuÃ§larÄ± Ã¶nbelleÄŸe alÄ±r.
@st.cache_data(ttl=86400) # Bir kez analiz edilen bir haberi 1 gÃ¼n boyunca tekrar analiz etme
def analyze_single_event(key, base_url, model, headline, url):
    client = OpenAI(api_key=key, base_url=base_url)
    prompt = f"""
    Sen lider bir sigorta hasar eksperisin. Sana verilen ÅŸu haberi analiz et:
    BaÅŸlÄ±k: "{headline}"
    Kaynak Link: "{url}"

    Bu habere dayanarak, aÅŸaÄŸÄ±daki JSON formatÄ±nda detaylÄ± bir hasar raporu oluÅŸtur:
    - "olay_tarihi": "YYYY-MM-DD"
    - "tesis_adi_ticari_unvan": "DoÄŸru ve tam ticari unvan."
    - "sehir_ilce": "Ä°l, Ä°lÃ§e"
    - "olay_tipi_ozet": "KÄ±sa olay tanÄ±mÄ±. Ã–rnek: 'Depo BÃ¶lÃ¼mÃ¼nde Ã‡Ä±kan BÃ¼yÃ¼k YangÄ±n'"
    - "hasar_detaylari_ve_etkisi": "Maddi hasar tahmini, can kaybÄ±/yaralÄ±, Ã¼retim etkisi gibi tÃ¼m detaylarÄ± iÃ§eren paragraf."
    - "orjinal_haber_metni": "Haberin en Ã¶nemli ve aÃ§Ä±klayÄ±cÄ± kÄ±smÄ± veya tamamÄ±."
    - "dogruluk_skoru_ve_gerekcelendirme": "YÃ¼zdesel skor ve gerekÃ§esi. Ã–rnek: '%95 - AA ve DHA tarafÄ±ndan teyit edildi.'"
    - "komsu_tesisler_risk_analizi": "YakÄ±n Ã§evredeki tesisler iÃ§in risk analizi."
    - "kaynak_linkleri": ["{url}"]
    - "latitude": OndalÄ±k formatta enlem.
    - "longitude": OndalÄ±k formatta boylam.
    """
    try:
        response = client.chat.completions.create(model=model, messages=[{"role": "user", "content": prompt}], max_tokens=4096, temperature=0.2)
        content = response.choices[0].message.content.strip()
        return json.loads(content)
    except Exception:
        return None

# ------------------------------------------------------------------------------
# 4. GÃ–RSEL ARAYÃœZ
# ------------------------------------------------------------------------------
st.header("ğŸ“ˆ En Son Tespit Edilen Hasarlar")

if st.button("En Son 15 OlayÄ± Bul ve Analiz Et", type="primary", use_container_width=True):
    with st.spinner("1. AÅŸama: En son olaylar ve haber linkleri taranÄ±yor..."):
        latest_events = find_latest_events(api_key, SELECTED_CONFIG["base_url"], SELECTED_CONFIG["model"])

    if not latest_events:
        st.info("Belirtilen kriterlere uygun, raporlanacak bir endÃ¼striyel olay tespit edilemedi.")
    else:
        st.success(f"**{len(latest_events)} adet potansiyel olay bulundu.** Åimdi her biri detaylÄ± olarak analiz ediliyor...")
        
        all_event_details = []
        progress_bar = st.progress(0, text="Analiz ilerlemesi...")

        for i, event in enumerate(latest_events):
            with st.spinner(f"2. AÅŸama: '{event['headline']}' haberi analiz ediliyor... ({i+1}/{len(latest_events)})"):
                event_details = analyze_single_event(api_key, SELECTED_CONFIG["base_url"], SELECTED_CONFIG["model"], event['headline'], event['url'])
                if event_details:
                    all_event_details.append(event_details)
            progress_bar.progress((i + 1) / len(latest_events), text="Analiz ilerlemesi...")
        
        progress_bar.empty()
        
        if not all_event_details:
            st.warning("Olaylar bulundu ancak detaylÄ± analiz sÄ±rasÄ±nda bir sorun oluÅŸtu.")
        else:
            events_df = pd.DataFrame(all_event_details)
            events_df['olay_tarihi'] = pd.to_datetime(events_df['olay_tarihi'])
            events_df['latitude'] = pd.to_numeric(events_df['latitude'], errors='coerce')
            events_df['longitude'] = pd.to_numeric(events_df['longitude'], errors='coerce')
            events_df = events_df.sort_values(by='olay_tarihi', ascending=False).reset_index(drop=True)

            st.subheader("Analiz Edilen Son Olaylar")
            for index, row in events_df.iterrows():
                with st.expander(f"**{row['olay_tarihi'].strftime('%d %B %Y')} - {row['tesis_adi_ticari_unvan']} ({row['sehir_ilce']})**"):
                    st.subheader(row['olay_tipi_ozet'])
                    col1, col2 = st.columns([3, 1]); col1.markdown("**Hasar DetaylarÄ± ve Etki**"); col1.write(row['hasar_detaylari_ve_etkisi']); col2.markdown("**DoÄŸruluk Skoru**"); col2.info(row['dogruluk_skoru_ve_gerekcelendirme'])
                    st.markdown("**Bulunan Haber Metni**"); st.text_area("", value=row['orjinal_haber_metni'], height=150, disabled=True, key=f"text_{index}")
                    st.markdown("**KomÅŸu Tesisler Ä°Ã§in Risk Analizi**"); st.warning(row['komsu_tesisler_risk_analizi'])
                    links_md = "".join([f"- [{link.split('//')[-1].split('/')[0]}]({link})\n" for link in row['kaynak_linkleri']])
                    st.markdown("**TÄ±klanabilir Kaynak Linkleri**\n" + links_md)

            st.header("ğŸ—ºï¸ OlaylarÄ±n Konumsal DaÄŸÄ±lÄ±mÄ±")
            map_df = events_df.dropna(subset=['latitude', 'longitude'])
            if not map_df.empty:
                map_center = [map_df['latitude'].mean(), map_df['longitude'].mean()]
                m = folium.Map(location=map_center, zoom_start=6)
                for _, row in map_df.iterrows():
                    folium.Marker([row['latitude'], row['longitude']], popup=f"<b>{row['tesis_adi_ticari_unvan']}</b>", tooltip=row['tesis_adi_ticari_unvan']).add_to(m)
                folium_static(m)

st.caption("Bu analiz, yapay zeka tarafÄ±ndan kamuya aÃ§Ä±k veriler ve X (Twitter) paylaÅŸÄ±mlarÄ± iÅŸlenerek oluÅŸturulmuÅŸtur.")
