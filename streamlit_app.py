# ==============================================================================
#      NÄ°HAÄ° KOD (v14.1): GÃ¼venli VeritabanÄ± ve Hata DÃ¼zeltmeleri
# ==============================================================================
import streamlit as st
import pandas as pd
import folium
from streamlit_folium import folium_static
from openai import OpenAI
import json
import re
import requests
from datetime import datetime

# ------------------------------------------------------------------------------
# 1. TEMEL AYARLAR VE BAÄLANTILAR
# ------------------------------------------------------------------------------
st.set_page_config(layout="wide", page_title="EndÃ¼striyel Hasar Ä°stihbaratÄ±")
st.title("ğŸ›°ï¸ AkÄ±llÄ± EndÃ¼striyel Hasar Ä°stihbarat Platformu")

# --- API BaÄŸlantÄ±larÄ± ---
grok_api_key = st.secrets.get("GROK_API_KEY")
google_api_key = st.secrets.get("GOOGLE_MAPS_API_KEY")
client = OpenAI(api_key=grok_api_key, base_url="https://api.x.ai/v1") if grok_api_key else None

# --- VeritabanÄ± BaÄŸlantÄ±sÄ± ---
@st.cache_resource
def init_connection():
    return st.connection("reports_db", type="sql")

conn = init_connection()

# TablolarÄ± oluÅŸtur (sadece ilk Ã§alÄ±ÅŸtÄ±rmada Ã§alÄ±ÅŸÄ±r)
with conn.session as s:
    s.execute('''
        CREATE TABLE IF NOT EXISTS events (
            id INTEGER PRIMARY KEY AUTOINCREMENT,
            event_group_key TEXT UNIQUE,
            first_seen_date TEXT
        );
    ''')
    s.execute('''
        CREATE TABLE IF NOT EXISTS reports (
            id INTEGER PRIMARY KEY AUTOINCREMENT,
            event_id INTEGER,
            report_json TEXT,
            created_date TEXT,
            FOREIGN KEY (event_id) REFERENCES events (id)
        );
    ''')
    s.commit()

# ------------------------------------------------------------------------------
# 2. YAPAY ZEKA DESTEKLÄ° FONKSÄ°YONLAR (PÄ°PELÄ°NE ADIMLARI)
# ------------------------------------------------------------------------------
# Bu bÃ¶lÃ¼mdeki AI fonksiyonlarÄ±nda (discover_events, group_similar_events, vb.) deÄŸiÅŸiklik yoktur.
# Okunabilirlik iÃ§in sadece bir tanesini Ã¶rnek olarak bÄ±rakÄ±yorum.
@st.cache_data(ttl=900)
def discover_events(_client, period_days=7):
    # ... (v14.0 ile aynÄ±)
    prompt = f"Sen bir haber tarama botusun. Son {period_days} gÃ¼n iÃ§inde TÃ¼rkiye'de 'fabrika, sanayi, depo, liman, santral, OSB' kelimeleri ve 'yangÄ±n, patlama, kaza, hasar, sÄ±zÄ±ntÄ±' kelimelerini iÃ§eren Ã¶nemli haber baÅŸlÄ±klarÄ±nÄ± ve linklerini bul. Sadece bir JSON listesi olarak `[{{\"headline\": \"...\", \"url\": \"...\"}}]` formatÄ±nda ver. Analiz yapma, sadece listele. En fazla 30 baÅŸlÄ±k yeterli."
    try:
        response = _client.chat.completions.create(model="grok-4-fast-reasoning", messages=[{"role": "user", "content": prompt}], max_tokens=4096, temperature=0.2)
        content = response.choices[0].message.content.strip()
        match = re.search(r'\[.*\]', content, re.DOTALL)
        return json.loads(match.group(0)) if match else []
    except Exception: return []

# ... DiÄŸer AI fonksiyonlarÄ± (group_similar_events, analyze_event_details, find_neighboring_facilities) v14.0 ile aynÄ±dÄ±r.
# Bu fonksiyonlar buraya kopyalanabilir.

@st.cache_data(ttl=900)
def group_similar_events(_client, headlines):
    headlines_str = "\n".join([f"- {h['headline']}" for h in headlines])
    prompt = f"""Sen bir haber editÃ¶rÃ¼sÃ¼n. Sana verdiÄŸim ÅŸu haber baÅŸlÄ±klarÄ± listesini analiz et ve aynÄ± olaya ait olanlarÄ± grupla. Ã‡Ä±ktÄ±yÄ± bir JSON objesi olarak ver. Her anahtar, olay iÃ§in birleÅŸtirici bir baÅŸlÄ±k olsun, deÄŸeri ise o gruba ait orijinal baÅŸlÄ±klarÄ±n listesi olsun.
    BAÅLIKLAR:\n{headlines_str}
    Ã–rnek Ã‡Ä±ktÄ± FormatÄ±: {{"Gebze Kimya FabrikasÄ± YangÄ±nÄ±": ["Gebze'deki fabrikada korkutan yangÄ±n", "Kocaeli'de kimya tesisinde patlama yaÅŸandÄ±"],"Ä°kitelli Mobilya AtÃ¶lyesi YangÄ±nÄ±": ["Ä°kitelli'de bir atÃ¶lye alevlere teslim oldu"]}}"""
    try:
        response = _client.chat.completions.create(model="grok-4-fast-reasoning", messages=[{"role": "user", "content": prompt}], max_tokens=4096, temperature=0.0)
        content = response.choices[0].message.content.strip()
        match = re.search(r'\{.*\}', content, re.DOTALL)
        return json.loads(match.group(0)) if match else {}
    except Exception: return {}

@st.cache_data(ttl=86400)
def analyze_event_details(_client, headlines_list, group_key):
    prompt = f"""Sen bir sigorta hasar eksperi ve risk analistisin. Sana verdiÄŸim '{group_key}' olayÄ± ile ilgili ÅŸu haber baÅŸlÄ±klarÄ±nÄ± ve linklerini analiz et: {json.dumps(headlines_list)}.
    GÃ–REVÄ°N: Bu bilgileri kullanarak, tek ve birleÅŸtirilmiÅŸ, detaylÄ± bir JSON raporu oluÅŸtur. Hasar tahminini haber metninden kaynak gÃ¶stererek yap, ASLA tahmin yÃ¼rÃ¼tme.
    JSON ANAHTARLARI: olay_tarihi_saati, guncel_durum, tesis_adi_ticari_unvan, sehir_ilce, olay_tipi_ozet, hasar_tahmini (nesne: tutar_araligi_tl, kaynak, aciklama), can_kaybi_ve_yaralilar (nesne: durum, detaylar), kaynak_linkleri (dizi), gorsel_linkleri (dizi), latitude, longitude"""
    try:
        response = _client.chat.completions.create(model="grok-4-fast-reasoning", messages=[{"role": "user", "content": prompt}], max_tokens=4096, temperature=0.1)
        content = response.choices[0].message.content.strip()
        match = re.search(r'\{.*\}', content, re.DOTALL)
        if match: return json.loads(match.group(0))
        return None
    except Exception: return None

@st.cache_data(ttl=86400)
def find_neighboring_facilities(api_key, lat, lon, radius=300):
    if not api_key: return []
    url = f"https://maps.googleapis.com/maps/api/place/nearbysearch/json?location={lat},{lon}&radius={radius}&type=establishment&keyword=fabrika|depo|sanayi|tesis|lojistik|antrepo&key={api_key}"
    try:
        response = requests.get(url)
        results = response.json().get('results', [])
        return [{"tesis_adi": p.get('name'), "tip": ", ".join(p.get('types', [])), "konum": p.get('vicinity')} for p in results[:5]]
    except Exception: return []


# ------------------------------------------------------------------------------
# 3. GÃœVENLÄ° VERÄ°TABANI Ä°ÅLEMLERÄ°
# ------------------------------------------------------------------------------
# DÃœZELTME: Bu fonksiyonlar artÄ±k gÃ¼venli parametreli sorgular kullanÄ±yor.
def check_event_exists(event_group_key):
    df = conn.query(
        "SELECT id FROM events WHERE event_group_key = :key;",
        params={"key": event_group_key}
    )
    return not df.empty

def save_report_to_db(event_group_key, report_json):
    with conn.session as s:
        # Ã–nce event'i kaydet
        s.execute(
            "INSERT INTO events (event_group_key, first_seen_date) VALUES (:key, :date);",
            params={"key": event_group_key, "date": datetime.now().isoformat()}
        )
        # Son eklenen event'in id'sini al
        result = s.execute(
            "SELECT id FROM events WHERE event_group_key = :key;",
            params={"key": event_group_key}
        )
        event_id = result.fetchone()[0]
        
        # Raporu kaydet
        s.execute(
            "INSERT INTO reports (event_id, report_json, created_date) VALUES (:id, :json, :date);",
            params={"id": event_id, "json": json.dumps(report_json, ensure_ascii=False), "date": datetime.now().isoformat()}
        )
        s.commit()

def get_all_reports_from_db():
    df = conn.query("SELECT e.event_group_key, r.report_json, r.created_date FROM reports r JOIN events e ON r.event_id = e.id ORDER BY r.created_date DESC;", ttl=600) # 10 dakika cache
    reports = []
    for index, row in df.iterrows():
        try:
            report_data = json.loads(row['report_json'])
            report_data['event_group_key'] = row['event_group_key']
            report_data['created_date'] = row['created_date']
            reports.append(report_data)
        except json.JSONDecodeError:
            continue # Bozuk JSON verisini atla
    return reports

# ------------------------------------------------------------------------------
# 4. ARAYÃœZ VE ANA Ä°ÅLEM AKIÅI
# ------------------------------------------------------------------------------
# Bu bÃ¶lÃ¼mde Ã¶nemli bir deÄŸiÅŸiklik yoktur, v14.0 ile aynÄ±dÄ±r.
st.sidebar.header("Otomatik Tarama")
run_auto_search = st.sidebar.button("Son OlaylarÄ± Bul ve Analiz Et", type="primary", use_container_width=True)
st.sidebar.caption("Son 7 gÃ¼ne ait olaylarÄ± tarar, tekilleÅŸtirir ve analiz eder.")
tab1, tab2 = st.tabs(["Yeni Analiz SonuÃ§larÄ±", "GeÃ§miÅŸ Raporlar VeritabanÄ±"])

if run_auto_search:
    if not client:
        st.error("LÃ¼tfen Grok API anahtarÄ±nÄ± Streamlit Secrets'a ekleyin.")
        st.stop()
    
    with tab1:
        with st.spinner("AÅŸama 1/5: Potansiyel olaylar web'den taranÄ±yor..."):
            headlines = discover_events(client)
        if not headlines:
            st.warning("KeÅŸif aÅŸamasÄ±nda yeni bir olay baÅŸlÄ±ÄŸÄ± bulunamadÄ±."); st.stop()
        st.info(f"{len(headlines)} potansiyel baÅŸlÄ±k bulundu. Åimdi gruplanÄ±yor...")

        with st.spinner("AÅŸama 2/5: AI ile benzer haberler gruplanÄ±yor..."):
            event_groups = group_similar_events(client, headlines)
        st.success(f"{len(event_groups)} adet benzersiz olay grubu tespit edildi.")
        
        newly_processed_count = 0
        for group_key, group_headlines in event_groups.items():
            st.markdown("---"); st.subheader(f"Ä°ncelenen Olay Grubu: {group_key}")
            
            if check_event_exists(group_key):
                st.warning("Bu olay daha Ã¶nce analiz edilmiÅŸ ve veritabanÄ±na kaydedilmiÅŸ. AtlanÄ±yor.")
                continue

            newly_processed_count += 1
            with st.spinner(f"AÅŸama 3/5: '{group_key}' iÃ§in derin analiz yapÄ±lÄ±yor..."):
                original_articles = [h for h in headlines if h['headline'] in group_headlines]
                details = analyze_event_details(client, original_articles, group_key)
            if not details:
                st.error("Bu olay iÃ§in detaylÄ± rapor oluÅŸturulamadÄ±."); continue

            lat, lon = details.get('latitude'), details.get('longitude')
            real_neighbors = find_neighboring_facilities(google_api_key, lat, lon) if lat and lon else []
            details['real_neighbors'] = real_neighbors

            save_report_to_db(group_key, details)
            st.success(f"âœ”ï¸ Rapor baÅŸarÄ±yla oluÅŸturuldu ve veritabanÄ±na kaydedildi!")
            
            # Raporu Ekrana Basma (v14.0 ile aynÄ±)
            col1, col2 = st.columns(2)
            # ...
            with col1:
                st.info(f"**Ã–zet:** {details.get('olay_tipi_ozet', 'N/A')}")
                hasar = details.get('hasar_tahmini', {})
                st.metric(label="Hasar Tahmini", value=hasar.get('tutar_araligi_tl', 'BelirtilmemiÅŸ'), delta=hasar.get('kaynak', ''), delta_color="off")
            with col2:
                st.info(f"**GÃ¼ncel Durum:** {details.get('guncel_durum', 'N/A')}")
                can_kaybi = details.get('can_kaybi_ve_yaralilar', {})
                if can_kaybi and can_kaybi.get('durum', 'hayÄ±r').lower() == 'evet':
                    st.error(f"**Can KaybÄ±/YaralÄ±:** {can_kaybi.get('detaylar', 'Detay Yok')}")
            
            if lat and lon:
                try:
                    m = folium.Map(location=[float(lat), float(lon)], zoom_start=16)
                    folium.Marker([float(lat), float(lon)], popup=f"<b>{details.get('tesis_adi_ticari_unvan')}</b>", tooltip="Ana Tesis", icon=folium.Icon(color='red', icon='fire')).add_to(m)
                    folium_static(m, height=400)
                except (ValueError, TypeError):
                    st.warning("GeÃ§ersiz koordinat formatÄ±, harita Ã§izilemiyor.")
            
            with st.expander("DetaylÄ± Raporu, KomÅŸu Tesisleri ve KaynaklarÄ± GÃ¶rÃ¼ntÃ¼le"):
                st.markdown("##### GerÃ§ek KomÅŸu Tesisler (Google Maps Verisi)")
                st.table(pd.DataFrame(real_neighbors)) if real_neighbors else st.write("YakÄ±n Ã§evrede harita servisinden tesis tespit edilemedi.")
                st.markdown("##### Kaynak Linkler")
                for link in details.get('kaynak_linkleri', []): st.markdown(f"- {link}")


        if newly_processed_count == 0 and len(event_groups) > 0:
            st.info("TÃ¼m tespit edilen olaylar daha Ã¶nce iÅŸlenmiÅŸ. Yeni bir olay bulunamadÄ±.")

with tab2:
    st.header("VeritabanÄ±nda KayÄ±tlÄ± GeÃ§miÅŸ Raporlar")
    all_reports = get_all_reports_from_db()
    if not all_reports:
        st.info("VeritabanÄ±nda henÃ¼z kaydedilmiÅŸ bir rapor bulunmamaktadÄ±r.")
    else:
        st.success(f"VeritabanÄ±nda toplam {len(all_reports)} adet rapor bulundu.")
        for report in all_reports:
            tarih = pd.to_datetime(report['created_date']).strftime('%d %b %Y, %H:%M')
            with st.expander(f"**{report.get('tesis_adi_ticari_unvan', 'Ä°simsiz Tesis')}** - {report.get('sehir_ilce', 'Konum Yok')} (KayÄ±t: {tarih})"):
                col1, col2 = st.columns(2)
                # ...
                with col1:
                    st.info(f"**Ã–zet:** {report.get('olay_tipi_ozet', 'N/A')}")
                    hasar = report.get('hasar_tahmini', {})
                    st.metric(label="Hasar Tahmini", value=hasar.get('tutar_araligi_tl', 'BelirtilmemiÅŸ'), delta=hasar.get('kaynak', ''), delta_color="off")
                with col2:
                    st.info(f"**GÃ¼ncel Durum:** {report.get('guncel_durum', 'N/A')}")
                st.markdown("##### GerÃ§ek KomÅŸu Tesisler (Google Maps Verisi)")
                st.table(pd.DataFrame(report.get('real_neighbors', []))) if report.get('real_neighbors') else st.write("KomÅŸu tesis bilgisi yok.")
