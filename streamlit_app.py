# ==============================================================================
#  NÄ°HAÄ° KOD (v52.0): Ã‡oklu-Sorgu Ä°stihbarat AjanÄ±
#  AMAÃ‡: KapsamÄ± geniÅŸletmek iÃ§in otomatik olarak Ã§ok sayÄ±da hedefli sorgu
#  oluÅŸturup, sonuÃ§larÄ± birleÅŸtirerek analiz etmek.
# ==============================================================================
import streamlit as st
import requests
from openai import OpenAI
import os
import time

# ------------------------------------------------------------------------------
# 1. TEMEL AYARLAR VE YAPILANDIRMA
# ------------------------------------------------------------------------------
st.set_page_config(layout="wide", page_title="Ã‡oklu-Sorgu Ä°stihbarat AjanÄ±")
st.title("ğŸ›°ï¸ Ã‡oklu-Sorgu Ä°stihbarat AjanÄ±")
st.info("Bu ajan, kapsamÄ± en Ã¼st dÃ¼zeye Ã§Ä±karmak iÃ§in TÃ¼rkiye'nin sanayi ÅŸehirleri ve farklÄ± risk tipleri bazÄ±nda otomatik olarak Ã§ok sayÄ±da hedefli arama yapar.")

# --- API AnahtarlarÄ±
GROK_API_KEY = st.secrets.get("GROK_API_KEY")
TAVILY_API_KEY = st.secrets.get("TAVILY_API_KEY")
grok_client = OpenAI(api_key=GROK_API_KEY, base_url="https://api.x.ai/v1") if GROK_API_KEY else None

# --- Arama Matrisi iÃ§in Sabitler
INDUSTRIAL_CITIES = ["Ä°stanbul", "Kocaeli", "Bursa", "Ä°zmir", "Ankara", "Gaziantep", "TekirdaÄŸ", "Konya", "Kayseri", "Adana", "Manisa", "Denizli"]
RISK_KEYWORDS = ["yangÄ±n", "patlama", "kaza", "sÄ±zÄ±ntÄ±", "gÃ¶Ã§Ã¼k"]

# ------------------------------------------------------------------------------
# 2. Ã‡EKÄ°RDEK FONKSÄ°YONLAR
# ------------------------------------------------------------------------------

@st.cache_data(ttl=3600)
def run_multi_query_search(date_option):
    """
    Ã–nceden tanÄ±mlanmÄ±ÅŸ ÅŸehir ve risk listelerine gÃ¶re Ã§ok sayÄ±da hedefli sorgu oluÅŸturur
    ve Tavily API ile aratarak birleÅŸik bir kanÄ±t dosyasÄ± dÃ¶ndÃ¼rÃ¼r.
    """
    if not TAVILY_API_KEY:
        st.error("Tavily API anahtarÄ± bulunamadÄ±.")
        return None
    
    # 1. Otomatik Sorgu Ãœretimi
    queries = []
    base_keywords = ["fabrika", "sanayi", "OSB", "depo", "tesis", "liman"]
    for city in INDUSTRIAL_CITIES:
        for risk in RISK_KEYWORDS:
            for keyword in base_keywords:
                 queries.append(f'"{city}" "{keyword}" "{risk}" son {date_option.lower()}')

    # 2. KatmanlÄ± Arama
    st.info(f"KapsamlÄ± bir analiz iÃ§in toplam {len(queries)} adet hedefli sorgu oluÅŸturuldu. Bu iÅŸlem biraz zaman alabilir.")
    progress_bar = st.progress(0, text="Hedefli aramalar baÅŸlatÄ±lÄ±yor...")
    
    all_results = {} # URL'leri key olarak kullanarak duplikeleri engelle
    for i, query in enumerate(queries):
        try:
            response = requests.post(
                "https://api.tavily.com/search",
                json={ "api_key": TAVILY_API_KEY, "query": query, "search_depth": "basic", "max_results": 3 }
            )
            response.raise_for_status()
            results = response.json().get('results', [])
            for result in results:
                if result['url'] not in all_results:
                    all_results[result['url']] = result
            
            # Her 10 sorguda bir API limitlerini aÅŸmamak iÃ§in kÄ±sa bir bekleme
            if (i + 1) % 10 == 0:
                time.sleep(1)

        except Exception as e:
            # Bir sorgu hata verirse devam et
            st.warning(f"'{query}' sorgusu iÅŸlenirken bir hata oluÅŸtu: {e}")
            continue
        finally:
            progress_bar.progress((i + 1) / len(queries), text=f"Sorgu {i+1}/{len(queries)} tamamlandÄ±: {query}")

    # 3. BirleÅŸik KanÄ±t DosyasÄ± OluÅŸturma
    context = "BÄ°RLEÅÄ°K KANIT DOSYASI:\n\n"
    for i, result in enumerate(all_results.values()):
        context += f"Kaynak {i+1}:\nBaÅŸlÄ±k: {result['title']}\nURL: {result['url']}\nÃ–zet: {result['content']}\n\n"
    
    return context

@st.cache_data(ttl=3600, show_spinner="Grok AI, toplanan kapsamlÄ± kanÄ±tlarÄ± analiz edip nihai raporu oluÅŸturuyor...")
def generate_final_report_from_comprehensive_data(_client, user_query, evidence_context):
    """
    Ã‡ok sayÄ±da aramadan toplanan birleÅŸik kanÄ±t dosyasÄ±nÄ± analiz eder.
    """
    if not _client:
        st.error("Grok API anahtarÄ± bulunamadÄ±.")
        return None
        
    prompt = f"""
    Sen, kanÄ±ta dayalÄ± Ã§alÄ±ÅŸan bir BaÅŸ Ä°stihbarat Analistisin. HalÃ¼sinasyona sÄ±fÄ±r toleransÄ±n var. Sadece sana sunulan BÄ°RLEÅÄ°K KANIT DOSYASI'ndaki bilgileri kullanacaksÄ±n.

    KULLANICININ ANA HEDEFÄ°: "{user_query}"

    SANA SUNULAN BÄ°RLEÅÄ°K KANIT DOSYASI (Onlarca farklÄ± aramadan toplanan sonuÃ§lar):
    ---
    {evidence_context}
    ---

    GÃ–REVÄ°N:
    1. YukarÄ±daki devasa kanÄ±t dosyasÄ±nÄ± dikkatlice incele.
    2. KullanÄ±cÄ±nÄ±n ana hedefini karÅŸÄ±layacak ÅŸekilde, bu kanÄ±tlara dayanarak, bulduÄŸun TÃœM olaylarÄ± iÃ§eren detaylÄ± bir tablo formatÄ±nda bir rapor oluÅŸtur.
    3. OlaylarÄ± birleÅŸtir ve duplicate (aynÄ± olayÄ±n farklÄ± haberleri) olanlarÄ± tek bir satÄ±rda Ã¶zetle. Åirket adÄ±nÄ± bulmaya Ã¶zellikle odaklan.
    4. Bir bilgi kanÄ±tlarda mevcut deÄŸilse, o hÃ¼creye "KanÄ±tlarda BelirtilmemiÅŸ" yaz. ASLA TAHMÄ°N YÃœRÃœTME.
    5. Referans URL sÃ¼tununa, bilgiyi aldÄ±ÄŸÄ±n en gÃ¼venilir kaynaÄŸÄ±n URL'ini ekle.

    Ä°STENEN Ã‡IKTI FORMATI:
    | SÄ±ra | Tarih | Åirket AdÄ± | AÃ§Ä±klama ve Teyit | HasarÄ±n Etkisi | Etkilenen Ã‡evre Tesisleri (DetaylÄ± Etki) | Referans URL |
    |------|-------|------------|-------------------|----------------|-------------------------------------------|--------------|
    """
    try:
        response = _client.chat.completions.create(
            model="grok-4-fast-reasoning", messages=[{"role": "user", "content": prompt}],
            max_tokens=4096, temperature=0.0, timeout=300.0
        )
        return response.choices[0].message.content
    except Exception as e:
        st.error(f"Grok AI ile rapor oluÅŸturulurken hata oluÅŸtu: {e}")
        return None

# ------------------------------------------------------------------------------
# 3. STREAMLIT ARAYÃœZÃœ
# ------------------------------------------------------------------------------

st.subheader("1. AdÄ±m: Arama Parametrelerini SeÃ§in")
date_option = st.selectbox(
    "Hangi Zaman AralÄ±ÄŸÄ±nÄ± Taramak Ä°stersiniz?",
    ("45 gÃ¼n", "3 ay", "6 ay", "1 yÄ±l")
)
user_query_for_grok = f"TÃ¼rkiye'de son {date_option} iÃ§inde gerÃ§ekleÅŸmiÅŸ tÃ¼m Ã¶nemli endÃ¼striyel hasarlarÄ± (fabrika, depo, OSB, liman, maden), firma adlarÄ±, etkileri ve Ã§evre tesisleri ile birlikte detaylÄ± bir ÅŸekilde listele."

st.subheader("2. AdÄ±m: AjanÄ± BaÅŸlatÄ±n")
if st.button("KapsamlÄ± AraÅŸtÄ±rma Yap ve Rapor OluÅŸtur", type="primary", use_container_width=True):
    if not TAVILY_API_KEY or not GROK_API_KEY:
        st.error("LÃ¼tfen hem Grok hem de Tavily API anahtarlarÄ±nÄ± eklediÄŸinizden emin olun.")
    else:
        st.session_state.final_report = None; st.session_state.evidence_context = None
        evidence = run_multi_query_search(date_option)
        if evidence and len(evidence) > 50: # EÄŸer hiÃ§ kanÄ±t bulunamazsa Grok'u boÅŸuna Ã§aÄŸÄ±rma
            st.session_state.evidence_context = evidence
            final_report = generate_final_report_from_comprehensive_data(grok_client, user_query_for_grok, evidence)
            st.session_state.final_report = final_report
        else:
            st.warning("YapÄ±lan kapsamlÄ± arama sonucunda analiz edilecek yeterli kanÄ±t bulunamadÄ±.")

# --- SONUÃ‡LARI GÃ–STER ---
if 'final_report' in st.session_state and st.session_state.final_report:
    st.markdown("---")
    st.subheader("Nihai Ä°stihbarat Raporu")
    st.markdown(st.session_state.final_report)

    with st.expander("AjanÄ±n Analiz EttiÄŸi Ham KanÄ±tlarÄ± GÃ¶r (Toplamda {} karakter)".format(len(st.session_state.get('evidence_context', '')))):
        st.text_area("Tavily'den Gelen BirleÅŸik KanÄ±t DosyasÄ±", st.session_state.get('evidence_context', ''), height=400)
