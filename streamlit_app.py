# ==============================================================================
#      NÄ°HAÄ° KOD (v25.0): Veri Ã‡ekme (Scraping) + Derin Analiz Mimarisi
# ==============================================================================
import streamlit as st
import pandas as pd
import folium
from streamlit_folium import folium_static
from openai import OpenAI
import json
import re
import requests
import feedparser
from urllib.parse import quote
from bs4 import BeautifulSoup

# ------------------------------------------------------------------------------
# 1. TEMEL AYARLAR
# ------------------------------------------------------------------------------
st.set_page_config(layout="wide", page_title="EndÃ¼striyel Hasar Analizi")
st.title("ğŸ›°ï¸ AkÄ±llÄ± EndÃ¼striyel Hasar Analiz Motoru")

# --- API BaÄŸlantÄ±larÄ± ---
grok_api_key = st.secrets.get("GROK_API_KEY")
google_api_key = st.secrets.get("GOOGLE_MAPS_API_KEY")
client = OpenAI(api_key=grok_api_key, base_url="https://api.x.ai/v1") if grok_api_key else None

# ------------------------------------------------------------------------------
# 2. Ã‡EKÄ°RDEK FONKSÄ°YONLAR
# ------------------------------------------------------------------------------

# AdÄ±m 1: Otomatik KeÅŸif - En son olayÄ± bulur
@st.cache_data(ttl=600)
def get_latest_event_candidate_from_rss():
    search_query = '("fabrika yangÄ±nÄ±" OR "sanayi tesisi" OR "OSB yangÄ±n" OR "liman kaza" OR "depo patlamasÄ±" OR "enerji santrali")'
    encoded_query = quote(search_query)
    rss_url = f"https://news.google.com/rss/search?q={encoded_query}+when:7d&hl=tr&gl=TR&ceid=TR:tr"
    try:
        feed = feedparser.parse(rss_url)
        if not feed.entries: return None
        latest_entry = feed.entries[0]
        return {"headline": latest_entry.title, "url": latest_entry.link}
    except Exception as e:
        st.error(f"RSS haber kaynaÄŸÄ±na eriÅŸilirken hata oluÅŸtu: {e}"); return None

# YENÄ° AdÄ±m 2: Veri Ã‡ekme - Haberin metnini internetten okur
@st.cache_data(ttl=3600)
def scrape_article_text(url):
    try:
        headers = {'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/91.0.4472.124 Safari/537.36'}
        response = requests.get(url, headers=headers, timeout=10)
        response.raise_for_status() # HTTP hatalarÄ±nÄ± kontrol et
        soup = BeautifulSoup(response.content, 'html.parser')
        
        # Haber metnini bulmak iÃ§in genel seÃ§iciler (selector)
        content_selectors = ['div.story-body', 'div.article-content', 'div.content', 'article']
        main_content = None
        for selector in content_selectors:
            main_content = soup.select_one(selector)
            if main_content:
                break
        
        if not main_content:
            main_content = soup.body # HiÃ§bir ÅŸey bulunamazsa body'yi al
        
        paragraphs = main_content.find_all('p')
        full_text = "\n".join([p.get_text(strip=True) for p in paragraphs])
        return full_text if full_text else "Metin Ã§ekilemedi."
    except Exception as e:
        st.warning(f"Haber metni Ã§ekilirken hata oluÅŸtu: {e}")
        return "Metin Ã§ekilemedi."

# AdÄ±m 3: Derin Analiz - Ã‡ekilmiÅŸ veri Ã¼zerinden AI'Ä± Ã§alÄ±ÅŸtÄ±rÄ±r
@st.cache_data(ttl=3600)
def get_detailed_report(_client, headline, url, article_text):
    prompt = f"""
    Sen, TÃ¼rkiye odaklÄ±, kanÄ±ta dayalÄ± ve aÅŸÄ±rÄ± detaycÄ± bir sigorta istihbarat analistisin.
    
    ANA GÃ–REVÄ°N: Sana aÅŸaÄŸÄ±da tam metnini verdiÄŸim haberi ve baÅŸlÄ±ÄŸÄ±nÄ± analiz et.
    - BAÅLIK: "{headline}"
    - HABER METNÄ°: "{article_text[:4000]}"

    Ä°KÄ°NCÄ°L GÃ–REVÄ°N: YukarÄ±daki metinden bulduÄŸun kilit isimler (potansiyel tesis adÄ±, ÅŸehir vb.) ile **X (Twitter) Ã¼zerinde ek bir arama yaparak** bilgileri doÄŸrula, ek detay, gÃ¶rgÃ¼ tanÄ±ÄŸÄ± ve kanÄ±t bul.

    NÄ°HAÄ° HEDEF: TopladÄ±ÄŸÄ±n TÃœM bilgileri (verilen haber metni ve X'ten bulduklarÄ±n) birleÅŸtirerek, aÅŸaÄŸÄ±daki JSON formatÄ±nda, mÃ¼mkÃ¼n olan en detaylÄ± ve dolu raporu oluÅŸtur.
    
    JSON NESNE YAPISI:
    - "tesis_adi": YÃ¼ksek doÄŸrulukla tespit edilmiÅŸ ticari unvan.
    - "tesis_adi_kanit": Tesis adÄ±nÄ±n geÃ§tiÄŸi cÃ¼mlenin veya X paylaÅŸÄ±mÄ±nÄ±n doÄŸrudan alÄ±ntÄ±sÄ±.
    - "sehir_ilce": OlayÄ±n yaÅŸandÄ±ÄŸÄ± yer.
    - "olay_tarihi": OlayÄ±n tarihi (YYYY-AA-GG).
    - "hasarin_nedeni": OlayÄ±n tahmini nedeni.
    - "hasarin_fiziksel_boyutu": HasarÄ±n fiziksel etkisi (yÃ¼zÃ¶lÃ§Ã¼mÃ¼, etkilenen birimler).
    - "maddi_hasar_tahmini": Parasal maddi hasar bilgisi ve kaynaÄŸÄ±.
    - "kar_kaybi_tahmini": Ãœretim durmasÄ± kaynaklÄ± kar kaybÄ± bilgisi ve kaynaÄŸÄ±.
    - "yapilan_mudahale": Resmi kurumlarÄ±n mÃ¼dahalesi (itfaiye sayÄ±sÄ±, sÃ¼re).
    - "guncel_durum": Ãœretim durdu mu, soruÅŸturma baÅŸladÄ± mÄ± gibi en son bilgiler.
    - "cevreye_etki": Duman, sÄ±zÄ±ntÄ± gibi Ã§evreye olan etkilerin Ã¶zeti.
    - "latitude", "longitude": Olay yerinin spesifik koordinatlarÄ± (tahmin de olabilir).
    - "gorsel_url": Olayla ilgili en net fotoÄŸrafÄ±n doÄŸrudan URL'si (.jpg, .png).
    - "kaynak_urller": KullandÄ±ÄŸÄ±n tÃ¼m haber ve X linklerinin listesi.
    """
    try:
        response = _client.chat.completions.create(model="grok-4-fast-reasoning", messages=[{"role": "user", "content": prompt}], max_tokens=4096, temperature=0.1)
        content = response.choices[0].message.content
        match = re.search(r'\{.*\}', content, re.DOTALL)
        return json.loads(match.group(0)) if match else None
    except Exception as e:
        st.error(f"Derin Analiz Motorunda Hata: {e}"); return None

# AdÄ±m 4: CoÄŸrafi ZenginleÅŸtirme
@st.cache_data(ttl=86400)
def find_neighboring_facilities(api_key, lat, lon, radius=500):
    if not api_key or not lat or not lon: return []
    try:
        url = f"https://maps.googleapis.com/maps/api/place/nearbysearch/json?location={float(lat)},{float(lon)}&radius={radius}&type=establishment&keyword=fabrika|depo|sanayi|tesis|lojistik|antrepo&key={api_key}"
        response = requests.get(url)
        results = response.json().get('results', [])
        neighbors = []
        for p in results[:10]:
            loc = p.get('geometry', {}).get('location', {})
            neighbors.append({"tesis_adi": p.get('name'), "tip": ", ".join(p.get('types', [])), "lat": loc.get('lat'), "lng": loc.get('lng')})
        return neighbors
    except Exception as e:
        st.warning(f"Google Places API hatasÄ±: {e}"); return []

# ------------------------------------------------------------------------------
# 3. ARAYÃœZ VE ANA Ä°ÅLEM AKIÅI
# ------------------------------------------------------------------------------
st.sidebar.header("Tek Olay Analizi")
run_analysis = st.sidebar.button("En Son Ã–nemli OlayÄ± Bul ve Analiz Et", type="primary", use_container_width=True)
st.sidebar.caption("En gÃ¼ncel ve Ã¶nemli tek bir olayÄ± bulur, metnini Ã§eker, derinlemesine analiz eder ve sunar.")

if run_analysis:
    if not client:
        st.error("LÃ¼tfen Grok API anahtarÄ±nÄ± Streamlit Secrets'a ekleyin."); st.stop()

    report = None
    with st.status("AkÄ±llÄ± Analiz sÃ¼reci yÃ¼rÃ¼tÃ¼lÃ¼yor...", expanded=True) as status:
        status.write("AÅŸama 1: Haber kaynaklarÄ± taranÄ±yor...")
        event_candidate = get_latest_event_candidate_from_rss()
        
        if not event_candidate:
            status.update(label="Hata! Uygun bir olay adayÄ± bulunamadÄ±.", state="error"); st.stop()
        
        status.write(f"Olay AdayÄ± Bulundu: **{event_candidate['headline']}**")
        status.write(f"AÅŸama 2: Haber metni '{event_candidate['url']}' adresinden Ã§ekiliyor...")
        
        article_text = scrape_article_text(event_candidate['url'])
        
        if "Metin Ã§ekilemedi" in article_text:
            status.update(label="Hata! Haber metni Ã§ekilemedi.", state="error"); st.stop()
        
        status.write("AÅŸama 3: AI Analiz Motoru Ã§alÄ±ÅŸtÄ±rÄ±lÄ±yor: Ã‡ekilen metin ve X Ã¼zerinde analiz baÅŸlÄ±yor...")
        report = get_detailed_report(client, event_candidate['headline'], event_candidate['url'], article_text)
        
        if report:
            status.write("AÅŸama 4: Rapor zenginleÅŸtiriliyor: Google Maps'ten komÅŸu tesis verileri Ã§ekiliyor...")
            report['komsu_tesisler_harita'] = find_neighboring_facilities(google_api_key, report.get('latitude'), report.get('longitude'))
            status.update(label="Analiz BaÅŸarÄ±yla TamamlandÄ±!", state="complete", expanded=False)
        else:
            status.update(label="Analiz BaÅŸarÄ±sÄ±z Oldu!", state="error")

    if report:
        st.markdown("---")
        st.header(f"Analiz Raporu: {report.get('tesis_adi', 'Ä°simsiz Tesis')}")
        
        if report.get('gorsel_url'):
            st.image(report['gorsel_url'], caption="Olay Yerinden GÃ¶rÃ¼ntÃ¼ (AI TarafÄ±ndan Bulundu)")

        st.info(f"**KanÄ±t:** *\"{report.get('tesis_adi_kanit', 'KanÄ±t bulunamadÄ±.')}\"*")
        
        col1, col2 = st.columns(2)
        with col1:
            st.warning(f"**HasarÄ±n Nedeni:** {report.get('hasarin_nedeni', 'N/A')}")
            st.warning(f"**Fiziksel Boyutu:** {report.get('hasarin_fiziksel_boyutu', 'N/A')}")
        with col2:
            st.success(f"**YapÄ±lan MÃ¼dahale:** {report.get('yapilan_mudahale', 'N/A')}")
            st.error(f"**GÃ¼ncel Durum:** {report.get('guncel_durum', 'N/A')}")

        col3, col4 = st.columns(2)
        with col3:
            st.metric(label="Maddi Hasar Tahmini", value=report.get('maddi_hasar_tahmini', 'Tespit Edilemedi'))
        with col4:
            st.metric(label="Kar KaybÄ± Tahmini", value=report.get('kar_kaybi_tahmini', 'Tespit Edilemedi'))
        
        st.info(f"**Ã‡evreye Etki:** {report.get('cevreye_etki', 'Tespit Edilemedi.')}")

        with st.expander("Harita, KomÅŸu Tesisler ve KaynaklarÄ± GÃ¶rÃ¼ntÃ¼le", expanded=True):
            lat, lon = report.get('latitude'), report.get('longitude')
            if lat and lon:
                try:
                    m = folium.Map(location=[float(lat), float(lon)], zoom_start=15, tiles="CartoDB positron")
                    folium.Marker([float(lat), float(lon)], popup=f"<b>{report.get('tesis_adi')}</b>", icon=folium.Icon(color='red', icon='fire')).add_to(m)
                    neighbors = report.get('komsu_tesisler_harita', [])
                    for neighbor in neighbors:
                        if neighbor.get('lat') and neighbor.get('lng'):
                            folium.Marker([neighbor['lat'], neighbor['lng']], popup=f"<b>{neighbor['tesis_adi']}</b><br><i>Tip: {neighbor['tip']}</i>", tooltip=neighbor['tesis_adi'], icon=folium.Icon(color='blue', icon='industry', prefix='fa')).add_to(m)
                    folium_static(m, height=500)
                except (ValueError, TypeError): st.warning("GeÃ§ersiz koordinat formatÄ±.")
            else:
                st.info("Rapor, harita Ã§izimi iÃ§in yeterli koordinat bilgisi iÃ§ermiyor.")

            st.markdown("##### KomÅŸu Tesisler (Google Harita Verisi)")
            st.table(pd.DataFrame(report.get('komsu_tesisler_harita', [])))
            st.markdown("##### Kaynak Linkler")
            for link in report.get('kaynak_urller', []): st.markdown(f"- {link}")
else:
    st.info("BaÅŸlamak iÃ§in lÃ¼tfen kenar Ã§ubuÄŸundaki butona tÄ±klayarak en son olayÄ±n analizini baÅŸlatÄ±n.")
