# ==============================================================================
#           NÄ°HAÄ° KOD (v7): PROFESYONEL RÄ°SK ANALÄ°Z PLATFORMU
# ==============================================================================
import streamlit as st
import pandas as pd
from datetime import datetime
import folium
from streamlit_folium import folium_static
from openai import OpenAI
import json
import re

# ------------------------------------------------------------------------------
# 1. TEMEL AYARLAR
# ------------------------------------------------------------------------------

st.set_page_config(layout="wide", page_title="EndÃ¼striyel Hasar Analizi")
st.title("ğŸš¨ AkÄ±llÄ± EndÃ¼striyel Hasar Takip Platformu")
st.markdown(f"**Son GÃ¼ncelleme:** {datetime.now().strftime('%d %B %Y, %H:%M')}")
st.markdown("---")

API_SERVICE = "Grok_XAI" 
API_CONFIGS = {"Grok_XAI": {"base_url": "https://api.x.ai/v1", "model": "grok-4-fast-reasoning"}}
SELECTED_CONFIG = API_CONFIGS[API_SERVICE]
API_KEY_NAME = "GROK_API_KEY"
api_key = st.secrets.get(API_KEY_NAME)

# ------------------------------------------------------------------------------
# 2. API BAÄLANTI KONTROLÃœ
# ------------------------------------------------------------------------------

@st.cache_data(ttl=3600)
def validate_api_key(key, base_url, model):
    if not key: return False, "API AnahtarÄ± bulunamadÄ±.", "LÃ¼tfen Streamlit Secrets ayarlarÄ±nÄ±zÄ± kontrol edin."
    try:
        OpenAI(api_key=key, base_url=base_url).chat.completions.create(model=model, messages=[{"role": "user", "content": "Test"}], max_tokens=10)
        return True, f"API baÄŸlantÄ±sÄ± baÅŸarÄ±lÄ±: **{API_SERVICE} ({model})**", ""
    except Exception as e:
        return False, "API BaÄŸlantÄ± HatasÄ±.", f"Detay: {e}"

st.sidebar.subheader("âš™ï¸ API BaÄŸlantÄ± Durumu")
is_valid, status_message, solution_message = validate_api_key(api_key, SELECTED_CONFIG["base_url"], SELECTED_CONFIG["model"])
if is_valid:
    st.sidebar.success(f"âœ… {status_message}")
else:
    st.sidebar.error(f"âŒ {status_message}"); st.sidebar.warning(solution_message); st.stop()

# ------------------------------------------------------------------------------
# 3. Ä°KÄ° AÅAMALI VERÄ° Ã‡EKME FONKSÄ°YONLARI
# ------------------------------------------------------------------------------

@st.cache_data(ttl=900)
def find_latest_events(key, base_url, model, event_count=15):
    client = OpenAI(api_key=key, base_url=base_url)
    current_date = datetime.now().strftime('%Y-%m-%d')
    prompt = f"""
    BugÃ¼nÃ¼n tarihi {current_date}. TÃ¼rkiye'de **son 3 ay iÃ§inde** yaÅŸanmÄ±ÅŸ endÃ¼striyel hasar olaylarÄ±nÄ± (fabrika yangÄ±nÄ±, patlama, kimyasal sÄ±zÄ±ntÄ± vb.) tara.
    BulduÄŸun tÃ¼m olaylar arasÄ±ndan, bana **en gÃ¼ncel {event_count} tanesini** listele. Bu listeyi oluÅŸtururken Ã¶zellikle **son 72 saatteki** olaylara mutlak Ã¶ncelik ver.
    Ã–ncelikli kaynaklarÄ±n X (Twitter)'daki resmi hesaplar (valilik, itfaiye) ve ulusal haber ajanslarÄ± (AA, DHA, Ä°HA) olsun.
    Ã‡Ä±ktÄ±yÄ±, aÅŸaÄŸÄ±daki anahtarlarÄ± iÃ§eren bir JSON dizisi olarak ver. Sadece listele, analiz yapma.
    - "headline": "OlayÄ±n kÄ±sa ve net baÅŸlÄ±ÄŸÄ±"
    - "url": "Habere ait tam ve tÄ±klanabilir birincil kaynak linki"
    """
    try:
        response = client.chat.completions.create(model=model, messages=[{"role": "user", "content": prompt}], max_tokens=2048, temperature=0.0)
        content = response.choices[0].message.content.strip()
        match = re.search(r'\[.*\]', content, re.DOTALL)
        return json.loads(match.group(0)) if match else []
    except Exception:
        return []

@st.cache_data(ttl=86400)
def analyze_single_event(key, base_url, model, headline, url):
    client = OpenAI(api_key=key, base_url=base_url)
    prompt = f"""
    Sen, X (Twitter) ve ulusal haber ajanslarÄ±nÄ± Ã§apraz kontrol ederek analiz yapan lider bir sigorta hasar eksperisin. Sana verilen ÅŸu haberi profesyonel bir gÃ¶zle analiz et:
    - BaÅŸlÄ±k: "{headline}"
    - Ana Kaynak Link: "{url}"

    Bu habere ve Ã§apraz kontrolle bulacaÄŸÄ±n ek bilgilere dayanarak, aÅŸaÄŸÄ±daki JSON formatÄ±nda detaylÄ± bir hasar raporu oluÅŸtur:
    - "olay_tarihi_saati": "YYYY-MM-DD HH:MM:SS" (Tahmini saat bilgisiyle)
    - "guncel_durum": "YangÄ±n kontrol altÄ±na alÄ±ndÄ±, soÄŸutma Ã§alÄ±ÅŸmalarÄ± devam ediyor" gibi en son durum bilgisi.
    - "tesis_adi_ticari_unvan": "Haberdeki ismi, Ticaret Sicil veya LinkedIn gibi kaynaklarla teyit ederek bulduÄŸun tam ve resmi ticari unvan."
    - "sehir_ilce": "Ä°l, Ä°lÃ§e"
    - "olay_tipi_ozet": "KÄ±sa ve profesyonel olay tanÄ±mÄ±."
    - "hasar_tahmini": {{"tutar_araligi_tl": "Ã–rn: 15-25 Milyon TL", "kaynak": "Haber metninde belirtildi / Ekspere dayalÄ± tahmin", "aciklama": "Kritik makinelerin ve stoklarÄ±n durumu hakkÄ±nda detay."}}
    - "can_kaybi_ve_yaralilar": {{"durum": "Evet / HayÄ±r / Bilinmiyor", "detaylar": "Varsa Ã¶len veya yaralanan kiÅŸilerin isimleri ve sayÄ±larÄ±."}}
    - "sigorta_teminatlari_analizi": {{"potansiyel_teminatlar": ["YangÄ±n", "Kar KaybÄ± (BI)", "Enkaz KaldÄ±rma"], "notlar": "PoliÃ§e detaylarÄ±na gÃ¶re deÄŸiÅŸebilecek profesyonel notlar."}}
    - "cevre_tesis_analizi": [{{"tesis_adi": "KomÅŸu Tesis A.Å.", "risk_faktoru": "YÃ¼ksek/Orta/DÃ¼ÅŸÃ¼k", "aciklama": "SÄ±Ã§rama, duman gibi risklerin analizi."}}]
    - "kaynak_linkleri": ["{url}", "https://buldugun.diger.kaynak/linki"]
    - "gorsel_linkleri": ["https://haberdeki.resim.linki/image.jpg"]
    - "latitude": OndalÄ±k formatta enlem.
    - "longitude": OndalÄ±k formatta boylam.
    """
    try:
        response = client.chat.completions.create(model=model, messages=[{"role": "user", "content": prompt}], max_tokens=4096, temperature=0.2)
        content = response.choices[0].message.content.strip()
        # Modellerin bazen JSON'u ```json ... ``` bloÄŸu iÃ§ine koyma eÄŸilimi vardÄ±r.
        match = re.search(r'\{.*\}', content, re.DOTALL)
        return json.loads(match.group(0)) if match else None
    except Exception:
        return None
        
# ------------------------------------------------------------------------------
# 4. YARDIMCI FONKSÄ°YONLAR VE GÃ–RSEL ARAYÃœZ
# ------------------------------------------------------------------------------

def parse_damage_to_radius(damage_str):
    if not isinstance(damage_str, str): return 100
    numbers = [int(s) for s in re.findall(r'\d+', damage_str)]
    if not numbers: return 100
    avg_damage = sum(numbers) / len(numbers)
    if "milyar" in damage_str.lower(): multiplier = 1000
    elif "milyon" in damage_str.lower(): multiplier = 1
    elif "bin" in damage_str.lower(): multiplier = 0.01
    else: multiplier = 0.00001
    radius = (avg_damage * multiplier) * 20 + 200 # Temel bir Ã¶lÃ§ekleme
    return min(radius, 5000) # Maksimum yarÄ±Ã§ap

st.header("ğŸ“ˆ En Son Tespit Edilen Hasarlar")
if st.button("En Son 15 OlayÄ± Bul ve Profesyonel Analiz Yap", type="primary", use_container_width=True):
    with st.spinner("1. AÅŸama: En son olaylar ve haber linkleri taranÄ±yor..."):
        latest_events = find_latest_events(api_key, SELECTED_CONFIG["base_url"], SELECTED_CONFIG["model"])

    if not latest_events:
        st.info("Belirtilen kriterlere uygun, raporlanacak bir endÃ¼striyel olay tespit edilemedi.")
    else:
        st.success(f"**{len(latest_events)} adet potansiyel olay bulundu.** Åimdi her biri iÃ§in derinlemesine analiz baÅŸlatÄ±lÄ±yor...")
        
        all_event_details, progress_bar = [], st.progress(0, text="Analiz ilerlemesi...")
        for i, event in enumerate(latest_events):
            progress_text = f"2. AÅŸama: '{event.get('headline', 'Bilinmeyen Olay')}' haberi analiz ediliyor... ({i+1}/{len(latest_events)})"
            progress_bar.progress((i + 1) / len(latest_events), text=progress_text)
            event_details = analyze_single_event(api_key, SELECTED_CONFIG["base_url"], SELECTED_CONFIG["model"], event.get('headline'), event.get('url'))
            if event_details: all_event_details.append(event_details)
        progress_bar.empty()
        
        if not all_event_details:
            st.warning("Olaylar bulundu ancak detaylÄ± analiz sÄ±rasÄ±nda bir sorun oluÅŸtu veya analiz sonucu geÃ§erli formatta deÄŸildi.")
        else:
            events_df = pd.DataFrame(all_event_details)
            events_df['olay_tarihi_saati'] = pd.to_datetime(events_df['olay_tarihi_saati'], errors='coerce')
            events_df = events_df.sort_values(by='olay_tarihi_saati', ascending=False).reset_index(drop=True)

            st.subheader("Analiz Edilen Son Olaylar Raporu")
            for index, row in events_df.iterrows():
                row = row.fillna('') # BoÅŸ alanlarda hata almamak iÃ§in
                with st.expander(f"**{row['olay_tarihi_saati'].strftime('%d %b %Y, %H:%M')} - {row['tesis_adi_ticari_unvan']} ({row['sehir_ilce']})**"):
                    st.subheader(row['olay_tipi_ozet'])
                    st.info(f"**GÃ¼ncel Durum:** {row['guncel_durum']}")
                    
                    if row.get('gorsel_linkleri') and isinstance(row['gorsel_linkleri'], list) and row['gorsel_linkleri']:
                        st.image(row['gorsel_linkleri'][0], caption="Olay Yerinden GÃ¶rÃ¼ntÃ¼", use_column_width=True)

                    st.markdown("---")
                    col1, col2 = st.columns(2)
                    with col1:
                        hasar_tahmini = row.get('hasar_tahmini', {})
                        st.markdown(f"##### Hasar Tahmini: `{hasar_tahmini.get('tutar_araligi_tl', 'BelirtilmemiÅŸ')}`")
                        st.caption(f"Kaynak: {hasar_tahmini.get('kaynak', 'Bilinmiyor')}")
                        st.write(hasar_tahmini.get('aciklama', ''))
                        
                        can_kaybi = row.get('can_kaybi_ve_yaralilar', {})
                        if can_kaybi.get('durum', 'Bilinmiyor').lower() == 'evet':
                            st.error(f"**Can KaybÄ± / YaralÄ±:** {can_kaybi.get('detaylar', 'Detay belirtilmemiÅŸ.')}")

                    with col2:
                        sigorta = row.get('sigorta_teminatlari_analizi', {})
                        st.markdown("##### Potansiyel Sigorta TeminatlarÄ±")
                        st.json(sigorta)

                    st.markdown("---")
                    st.markdown("##### Ã‡evre Tesisler Ä°Ã§in Risk Analizi")
                    st.table(pd.DataFrame(row['cevre_tesis_analizi']))
                    
                    st.markdown("---")
                    st.markdown("##### TÄ±klanabilir Kaynak Linkleri")
                    links_md = "".join([f"- [{link.split('//')[-1].split('/')[0]}]({link})\n" for link in row.get('kaynak_linkleri', [])])
                    st.markdown(links_md)

            st.header("ğŸ—ºï¸ OlaylarÄ±n Konumsal ve BÃ¼yÃ¼klÃ¼k DaÄŸÄ±lÄ±mÄ±")
            map_df = events_df.dropna(subset=['latitude', 'longitude'])
            if not map_df.empty:
                map_center = [map_df['latitude'].mean(), map_df['longitude'].mean()]
                m = folium.Map(location=map_center, zoom_start=6, tiles="CartoDB positron")
                for _, row in map_df.iterrows():
                    hasar = row.get('hasar_tahmini', {})
                    radius = parse_damage_to_radius(hasar.get('tutar_araligi_tl', ''))
                    popup_html = f"""
                    <h6>{row['tesis_adi_ticari_unvan']}</h6>
                    <b>Durum:</b> {row['guncel_durum']}<br>
                    <b>Hasar Tahmini:</b> {hasar.get('tutar_araligi_tl', 'N/A')}
                    """
                    folium.Circle(
                        location=[row['latitude'], row['longitude']],
                        radius=radius,
                        color='crimson',
                        fill=True,
                        fill_color='crimson',
                        popup=folium.Popup(popup_html, max_width=300)
                    ).add_to(m)
                folium_static(m, width=None, height=600)
